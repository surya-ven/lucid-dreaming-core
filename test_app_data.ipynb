{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371fc79b",
   "metadata": {},
   "source": [
    "\n",
    "# View Lucid Dreaming Core Session Data\n",
    "\n",
    "This notebook loads and visualizes data recorded by the `app/main.py` application.\n",
    "It reads the `session_metadata.npz` file for session information and then loads the corresponding\n",
    "`eeg_eog_data.dat` and `aux_sensor_data.dat` binary files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5e106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from datetime import datetime\n",
    "from frenztoolkit.reader import load_experiment\n",
    "\n",
    "# Configure matplotlib for inline plotting\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-v0_8-whitegrid') # Using a seaborn style for better aesthetics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8ce9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Configuration & Session Selection ---\n",
    "BASE_RECORDING_FOLDER = \"app/recorded_data\"\n",
    "METADATA_FILENAME = \"session_metadata.npz\"\n",
    "EEG_EOG_DATA_FILENAME = \"eeg_eog_data.dat\"\n",
    "AUX_SENSOR_DATA_FILENAME = \"aux_sensor_data.dat\"\n",
    "EEG_DATA_TYPE = np.float32 # Should match what's in main.py\n",
    "\n",
    "def list_session_folders(base_folder):\n",
    "    if not os.path.isdir(base_folder):\n",
    "        print(f\"Error: Base recording folder not found: {base_folder}\")\n",
    "        return []\n",
    "    sessions = sorted([d for d in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, d))], reverse=True)\n",
    "    return sessions\n",
    "\n",
    "available_sessions = list_session_folders(BASE_RECORDING_FOLDER)\n",
    "if not available_sessions:\n",
    "    print(f\"No session folders found in {BASE_RECORDING_FOLDER}\")\n",
    "else:\n",
    "    print(\"Available sessions:\")\n",
    "    for i, session_id in enumerate(available_sessions):\n",
    "        print(f\"{i}: {session_id}\")\n",
    "    \n",
    "    # Select a session (e.g., the latest one)\n",
    "    selected_session_index = 0 # Or use input() for user to choose\n",
    "    if 0 <= selected_session_index < len(available_sessions):\n",
    "        SESSION_FOLDER_NAME = available_sessions[selected_session_index]\n",
    "        SESSION_PATH = os.path.join(BASE_RECORDING_FOLDER, SESSION_FOLDER_NAME)\n",
    "        print(f\"\\nSelected session: {SESSION_FOLDER_NAME}\")\n",
    "        print(f\"Session path: {SESSION_PATH}\")\n",
    "    else:\n",
    "        print(\"Invalid session index selected.\")\n",
    "        SESSION_PATH = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aaf47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load Metadata --- \n",
    "metadata = None\n",
    "if SESSION_PATH and os.path.isdir(SESSION_PATH):\n",
    "    metadata_filepath = os.path.join(SESSION_PATH, METADATA_FILENAME)\n",
    "    if os.path.exists(metadata_filepath):\n",
    "        try:\n",
    "            metadata = np.load(metadata_filepath, allow_pickle=True)\n",
    "            print(\"\\n--- Session Metadata ---\")\n",
    "            for key, value in metadata.items():\n",
    "                if key not in ['scores', 'eeg_eog_data_info', 'aux_sensor_data_info'] and not key.startswith(\"metadata_\"):\n",
    "                    print(f\"{key}: {value}\")\n",
    "            \n",
    "            if 'eeg_eog_data_info' in metadata:\n",
    "                print(\"\\nEEG/EOG Data Info:\")\n",
    "                for k,v in metadata['eeg_eog_data_info'].item().items(): # .item() if it's a 0-d array object\n",
    "                    print(f\"  {k}: {v}\")\n",
    "            if 'aux_sensor_data_info' in metadata:\n",
    "                print(\"\\nAuxiliary Sensor Data Info:\")\n",
    "                for k,v in metadata['aux_sensor_data_info'].item().items():\n",
    "                    print(f\"  {k}: {v}\")\n",
    "            \n",
    "            # Store for later use\n",
    "            eeg_eog_info = metadata['eeg_eog_data_info'].item() if 'eeg_eog_data_info' in metadata else None\n",
    "            aux_info = metadata['aux_sensor_data_info'].item() if 'aux_sensor_data_info' in metadata else None\n",
    "            sampling_frequency = metadata['sampling_frequency_hz'].item() if 'sampling_frequency_hz' in metadata else 250.0\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading metadata file {metadata_filepath}: {e}\")\n",
    "            metadata = None\n",
    "    else:\n",
    "        print(f\"Metadata file not found: {metadata_filepath}\")\n",
    "else:\n",
    "    print(\"Session path not set or invalid.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2066b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Function to Load .dat Files ---\n",
    "def load_dat_file(filepath, num_channels, total_samples, dtype=np.float32):\n",
    "    if not os.path.exists(filepath):\n",
    "        print(f\"Data file not found: {filepath}\")\n",
    "        return None\n",
    "    try:\n",
    "        data_flat = np.fromfile(filepath, dtype=dtype)\n",
    "        # Expected number of elements\n",
    "        expected_elements = num_channels * total_samples\n",
    "        if data_flat.size != expected_elements:\n",
    "            print(f\"Warning: File size mismatch for {filepath}. Expected {expected_elements} elements, got {data_flat.size}.\")\n",
    "            # Attempt to reshape with actual elements, might lead to incorrect total_samples if file is corrupt/incomplete\n",
    "            # For robust handling, one might need to adjust total_samples or num_channels based on data_flat.size\n",
    "            # For now, we'll try to reshape with the number of samples that fits the channel count\n",
    "            if data_flat.size % num_channels == 0:\n",
    "                actual_total_samples = data_flat.size // num_channels\n",
    "                if actual_total_samples != total_samples:\n",
    "                    print(f\"Adjusting total samples for {filepath} from {total_samples} to {actual_total_samples} based on file size.\")\n",
    "                total_samples = actual_total_samples\n",
    "            else:\n",
    "                print(f\"Error: Cannot reshape data for {filepath} as size {data_flat.size} is not divisible by num_channels {num_channels}.\")\n",
    "                return None\n",
    "        \n",
    "        # Reshape to (num_channels, total_samples)\n",
    "        # Data was written as (channels, samples_in_block).tobytes(), so it's C-contiguous.\n",
    "        reshaped_data = data_flat.reshape(num_channels, total_samples)\n",
    "        return reshaped_data\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading or reshaping data file {filepath}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec29810",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load EEG/EOG Data ---\n",
    "eeg_eog_data_loaded = None\n",
    "if metadata and eeg_eog_info and SESSION_PATH:\n",
    "    eeg_eog_data_filepath = os.path.join(SESSION_PATH, EEG_EOG_DATA_FILENAME)\n",
    "    num_eeg_eog_channels = eeg_eog_info['num_channels']\n",
    "    \n",
    "    if 'metadata_eeg_eog_sample_counts' in metadata:\n",
    "        total_eeg_eog_samples = np.sum(metadata['metadata_eeg_eog_sample_counts'])\n",
    "        if total_eeg_eog_samples > 0:\n",
    "            eeg_eog_data_loaded = load_dat_file(eeg_eog_data_filepath, num_eeg_eog_channels, total_eeg_eog_samples, dtype=EEG_DATA_TYPE)\n",
    "            if eeg_eog_data_loaded is not None:\n",
    "                print(f\"\\nLoaded EEG/EOG data. Shape: {eeg_eog_data_loaded.shape}\")\n",
    "    else:\n",
    "        # We know the num channels and the data is 32-bit float\n",
    "        # If sample counts are not found, we can calculate the total samples based on the file size\n",
    "        file_size = os.path.getsize(eeg_eog_data_filepath)\n",
    "        expected_elements = file_size // (num_eeg_eog_channels * np.dtype(EEG_DATA_TYPE).itemsize)\n",
    "        print(f\"File size: {file_size} bytes, expected elements: {expected_elements}\")\n",
    "        if expected_elements > 0:\n",
    "            eeg_eog_data_loaded = load_dat_file(eeg_eog_data_filepath, num_eeg_eog_channels, expected_elements, dtype=EEG_DATA_TYPE)\n",
    "            if eeg_eog_data_loaded is not None:\n",
    "                print(f\"\\nLoaded EEG/EOG data. Shape: {eeg_eog_data_loaded.shape}\")\n",
    "        else:\n",
    "            print(\"EEG/EOG sample counts not found in metadata.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae29cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print First 5 Rows of EEG/EOG Data ---\n",
    "if eeg_eog_data_loaded is not None:\n",
    "    print(\"First 5 rows of EEG/EOG data (channels x samples):\")\n",
    "    print(eeg_eog_data_loaded[:4, :])\n",
    "else:\n",
    "    print(\"EEG/EOG data not loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ae00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Load Auxiliary Sensor Data ---\n",
    "aux_data_loaded = None\n",
    "if metadata and aux_info and SESSION_PATH:\n",
    "    aux_data_filepath = os.path.join(SESSION_PATH, AUX_SENSOR_DATA_FILENAME)\n",
    "    num_aux_channels = aux_info['num_channels']\n",
    "    \n",
    "    if 'metadata_aux_sample_counts' in metadata:\n",
    "        total_aux_samples = np.sum(metadata['metadata_aux_sample_counts'])\n",
    "        if total_aux_samples > 0:\n",
    "            aux_data_loaded = load_dat_file(aux_data_filepath, num_aux_channels, total_aux_samples, dtype=EEG_DATA_TYPE)\n",
    "            if aux_data_loaded is not None:\n",
    "                print(f\"\\nLoaded Auxiliary sensor data. Shape: {aux_data_loaded.shape}\")\n",
    "        else:\n",
    "            print(\"No Auxiliary sensor samples recorded according to metadata.\")\n",
    "    else:\n",
    "        # We know the num channels and the data is 32-bit float\n",
    "        # If sample counts are not found, we can calculate the total samples based on the file size\n",
    "        file_size = os.path.getsize(aux_data_filepath)\n",
    "        expected_elements = file_size // (num_aux_channels * np.dtype(EEG_DATA_TYPE).itemsize)\n",
    "        print(f\"File size: {file_size} bytes, expected elements: {expected_elements}\")\n",
    "        if expected_elements > 0:\n",
    "            aux_data_loaded = load_dat_file(aux_data_filepath, num_aux_channels, expected_elements, dtype=EEG_DATA_TYPE)\n",
    "            if aux_data_loaded is not None:\n",
    "                print(f\"\\nLoaded Auxiliary sensor data. Shape: {aux_data_loaded.shape}\")\n",
    "        else:\n",
    "            print(\"Auxiliary sensor sample counts not found in metadata.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63534da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Print First 5 Rows of Auxiliary Sensor Data ---\n",
    "if aux_data_loaded is not None:\n",
    "    print(\"First 5 rows of Auxiliary sensor data (channels x samples):\")\n",
    "    print(aux_data_loaded[:5, :])\n",
    "else:\n",
    "    print(\"Auxiliary sensor data not loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f9542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = load_experiment(\n",
    "#     \"app/recorded_data/20250528_021725_552841/1748413052.088846\")\n",
    "# # If data is loaded, print some basic information\n",
    "\n",
    "# print(len(data.get(\"SCORE\").get(\"array__sleep_stage\")))\n",
    "# sleep_stages = data.get(\"SCORE\").get(\"array__sleep_stage\")\n",
    "# loop through sleep stage and print if value is 3\n",
    "# if sleep_stages is not None:\n",
    "#     print(\"\\n--- Sleep Stages from Frenz Toolkit Data ---\")\n",
    "#     for i, stage in enumerate(sleep_stages):\n",
    "#         if stage == 3:  # REM sleep stage\n",
    "#             print(f\"Sleep Stage {i}: {stage} (REM)\")\n",
    "\n",
    "# --- Display Scores and Audio Cues ---\n",
    "if metadata and 'scores' in metadata and 'session_start_iso' in metadata:\n",
    "    scores_dict = metadata['scores'].item()\n",
    "    print(metadata['session_start_iso'])\n",
    "    session_start_iso_str = str(metadata['session_start_iso'].item())\n",
    "    audio_cue_timestamps_abs = metadata.get('audio_cue_timestamps') \n",
    "\n",
    "    # --- Plot Configuration ---\n",
    "    AUDIO_CUE_PRE_DELAY_S = 5.0  \n",
    "    AUDIO_CUES_PER_SEQUENCE = 2 \n",
    "    PLOT_SLICE_START_S = None  # Or specify a start time in seconds, e.g., 0\n",
    "    PLOT_SLICE_END_S = None    # Or specify an end time in seconds, e.g., 1800\n",
    "    SESSION_END_ISO_STR = \"2025-05-27T07:52:48.483307\" # Provided session end time, set to None to use EEG sample based calculation\n",
    "    # --- End Plot Configuration ---\n",
    "\n",
    "    print(\"\\n--- Saved Scores (from session_metadata.npz) ---\")\n",
    "    for score_name, score_array in scores_dict.items():\n",
    "        if isinstance(score_array, np.ndarray) and score_array.size > 10:\n",
    "            print(f\"\\nScore: {score_name} (Length: {len(score_array) if hasattr(score_array, '__len__') else 'N/A'}), First 10 values: {score_array[:10]}\")\n",
    "        else:\n",
    "            print(f\"\\nScore: {score_name} (Length: {len(score_array) if hasattr(score_array, '__len__') else 'N/A'})\")\n",
    "            print(score_array)\n",
    "\n",
    "    sleep_stages_all = scores_dict.get(\"array__sleep_stage\")\n",
    "\n",
    "    if sleep_stages_all is not None and hasattr(sleep_stages_all, '__len__') and len(sleep_stages_all) > 0:\n",
    "        try:\n",
    "            session_start_dt = datetime.fromisoformat(session_start_iso_str)\n",
    "            session_start_timestamp = session_start_dt.timestamp()\n",
    "            valid_start_time = True\n",
    "        except ValueError:\n",
    "            print(f\"Error: session_start_iso '{session_start_iso_str}' is not a valid ISO format. Cannot calculate relative cue times or adjusted interval from session end.\")\n",
    "            valid_start_time = False\n",
    "\n",
    "        SLEEP_STAGE_INTERVAL_S = 30.0 \n",
    "        sleep_stage_time_axis_full_s = np.arange(len(sleep_stages_all)) * SLEEP_STAGE_INTERVAL_S\n",
    "\n",
    "        # --- Apply Slicing for First Plot --- \n",
    "        slice_indices = np.ones(len(sleep_stages_all), dtype=bool)\n",
    "        \n",
    "        # Determine xlim for the first plot\n",
    "        xlim_start_orig = PLOT_SLICE_START_S if PLOT_SLICE_START_S is not None else (sleep_stage_time_axis_full_s[0] if len(sleep_stage_time_axis_full_s) > 0 else 0)\n",
    "        xlim_end_orig = PLOT_SLICE_END_S if PLOT_SLICE_END_S is not None else (sleep_stage_time_axis_full_s[-1] + SLEEP_STAGE_INTERVAL_S if len(sleep_stage_time_axis_full_s) > 0 else 0)\n",
    "\n",
    "        if PLOT_SLICE_START_S is not None:\n",
    "            slice_indices &= (sleep_stage_time_axis_full_s + SLEEP_STAGE_INTERVAL_S > PLOT_SLICE_START_S) \n",
    "        if PLOT_SLICE_END_S is not None:\n",
    "            slice_indices &= (sleep_stage_time_axis_full_s < PLOT_SLICE_END_S) \n",
    "            \n",
    "        sleep_stages_orig_plot = sleep_stages_all[slice_indices]\n",
    "        sleep_stage_time_axis_orig_plot_s = sleep_stage_time_axis_full_s[slice_indices]\n",
    "\n",
    "        if len(sleep_stages_orig_plot) == 0:\n",
    "            print(f\"No sleep stage data in the selected slice for the original plot: {PLOT_SLICE_START_S}s - {PLOT_SLICE_END_S}s. Cannot plot.\")\n",
    "        else:\n",
    "            print(\"\\n--- Generating Original Plot (30s Interval) ---\")\n",
    "            plt.figure(figsize=(16, 6)) \n",
    "            \n",
    "            sleep_stage_colors = {\n",
    "                -1: 'gray', 0: 'lightblue', 1: 'blue', 2: 'darkblue', 3: 'purple'\n",
    "            }\n",
    "            sleep_stage_labels = {\n",
    "                -1: 'Undefined', 0: 'Awake', 1: 'Light', 2: 'Deep', 3: 'REM'\n",
    "            }\n",
    "            \n",
    "            unique_stages_in_data = np.unique(sleep_stages_all) \n",
    "            for stage_val in unique_stages_in_data:\n",
    "                if stage_val in sleep_stage_labels:\n",
    "                     plt.bar(0, 0, width=0, color=sleep_stage_colors.get(stage_val, 'black'), label=f\"Stage: {sleep_stage_labels[stage_val]}\")\n",
    "\n",
    "            for i, stage in enumerate(sleep_stages_orig_plot):\n",
    "                start_time = sleep_stage_time_axis_orig_plot_s[i]\n",
    "                bar_width = SLEEP_STAGE_INTERVAL_S\n",
    "                \n",
    "                effective_bar_start = start_time\n",
    "                if PLOT_SLICE_START_S is not None and start_time < PLOT_SLICE_START_S:\n",
    "                    effective_bar_start = PLOT_SLICE_START_S\n",
    "                    bar_width = (start_time + SLEEP_STAGE_INTERVAL_S) - PLOT_SLICE_START_S\n",
    "                if PLOT_SLICE_END_S is not None and start_time + SLEEP_STAGE_INTERVAL_S > PLOT_SLICE_END_S:\n",
    "                    if effective_bar_start == PLOT_SLICE_START_S : \n",
    "                         bar_width = PLOT_SLICE_END_S - PLOT_SLICE_START_S if start_time < PLOT_SLICE_START_S else PLOT_SLICE_END_S - start_time\n",
    "                    else: \n",
    "                        bar_width = PLOT_SLICE_END_S - start_time\n",
    "\n",
    "                if bar_width <= 0: continue \n",
    "                \n",
    "                color = sleep_stage_colors.get(stage, 'black') \n",
    "                plt.bar(effective_bar_start, bottom=stage-0.4, height=0.8, width=bar_width, \n",
    "                        color=color, align='edge', alpha=0.7)\n",
    "            \n",
    "            current_ylim = plt.ylim()\n",
    "\n",
    "            plotted_cues = False\n",
    "            plotted_initiations = False\n",
    "            if valid_start_time and audio_cue_timestamps_abs is not None and hasattr(audio_cue_timestamps_abs, '__len__') and len(audio_cue_timestamps_abs) > 0:\n",
    "                if not isinstance(audio_cue_timestamps_abs, np.ndarray) or audio_cue_timestamps_abs.dtype != np.float64:\n",
    "                     audio_cue_timestamps_abs = np.array(audio_cue_timestamps_abs, dtype=np.float64)\n",
    "                \n",
    "                relative_audio_cue_times_s_all = audio_cue_timestamps_abs - session_start_timestamp\n",
    "                \n",
    "                cue_slice_indices = (relative_audio_cue_times_s_all >= xlim_start_orig) & (relative_audio_cue_times_s_all <= xlim_end_orig)\n",
    "                relative_audio_cue_times_s_plot = relative_audio_cue_times_s_all[cue_slice_indices]\n",
    "\n",
    "                if len(relative_audio_cue_times_s_plot) > 0:\n",
    "                    plt.vlines(relative_audio_cue_times_s_plot, ymin=current_ylim[0], ymax=current_ylim[1], \n",
    "                               colors='red', linestyles='dashed', label='Audio Cue Fired', zorder=5, alpha=0.8)\n",
    "                    plotted_cues = True\n",
    "\n",
    "                audio_cue_initiation_times_s_all = []\n",
    "                if len(relative_audio_cue_times_s_all) >= AUDIO_CUES_PER_SEQUENCE: \n",
    "                    for i in range(0, len(relative_audio_cue_times_s_all), AUDIO_CUES_PER_SEQUENCE):\n",
    "                        if i < len(relative_audio_cue_times_s_all):\n",
    "                            first_cue_in_sequence_time = relative_audio_cue_times_s_all[i]\n",
    "                            initiation_time = first_cue_in_sequence_time - AUDIO_CUE_PRE_DELAY_S\n",
    "                            audio_cue_initiation_times_s_all.append(initiation_time)\n",
    "                \n",
    "                initiation_slice_indices = (np.array(audio_cue_initiation_times_s_all) >= xlim_start_orig) & (np.array(audio_cue_initiation_times_s_all) <= xlim_end_orig)\n",
    "                audio_cue_initiation_times_s_plot = np.array(audio_cue_initiation_times_s_all)[initiation_slice_indices]\n",
    "                \n",
    "                if len(audio_cue_initiation_times_s_plot) > 0:\n",
    "                    plt.vlines(audio_cue_initiation_times_s_plot, ymin=current_ylim[0], ymax=current_ylim[1], \n",
    "                               colors='green', linestyles='dotted', label='Audio Cue Sequence Initiated', zorder=4, alpha=0.9)\n",
    "                    plotted_initiations = True\n",
    "            \n",
    "            plt.title(\"Sleep Stages and Audio Cues (30s Interval - from session_metadata.npz)\")\n",
    "            plt.xlabel(f\"Time from Session Start (seconds)\") \n",
    "            plt.ylabel(\"Sleep Stage\")\n",
    "            plt.yticks([-1, 0, 1, 2, 3], ['Undefined', 'Awake', 'Light', 'Deep', 'REM'])\n",
    "            plt.legend(loc='upper right') \n",
    "            plt.grid(True, axis='x') \n",
    "            plt.ylim(current_ylim) \n",
    "            plt.xlim(xlim_start_orig, xlim_end_orig)\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "            if valid_start_time and audio_cue_timestamps_abs is not None:\n",
    "                if hasattr(audio_cue_timestamps_abs, '__len__') and len(audio_cue_timestamps_abs) > 0:\n",
    "                    print(f\"\\nOriginal Plot - Audio Cues Fired (absolute timestamps, full session): {audio_cue_timestamps_abs}\")\n",
    "                    print(f\"Original Plot - Audio Cues Fired (seconds from session start, full session): {np.round(relative_audio_cue_times_s_all, 2)}\")\n",
    "                    if plotted_cues: \n",
    "                         print(f\"Original Plot - Audio Cues Fired (seconds from session start, PLOTTED SLICE): {np.round(relative_audio_cue_times_s_plot, 2)}\")\n",
    "                    if audio_cue_initiation_times_s_all: \n",
    "                        print(f\"Original Plot - Audio Cue Sequence Initiations (seconds from session start, full session): {np.round(audio_cue_initiation_times_s_all, 2)}\")\n",
    "                    if plotted_initiations: \n",
    "                        print(f\"Original Plot - Audio Cue Sequence Initiations (seconds from session start, PLOTTED SLICE): {np.round(audio_cue_initiation_times_s_plot, 2)}\")\n",
    "                elif not plotted_cues and not plotted_initiations: \n",
    "                    print(\"\\nOriginal Plot - Audio cue timestamp data found but was empty or all cues/initiations outside selected slice. No cues plotted.\")\n",
    "            elif audio_cue_timestamps_abs is None:\n",
    "                 print(\"\\nOriginal Plot - Audio cue timestamps (key 'audio_cue_timestamps') not found in metadata. Cannot plot cues.\")\n",
    "        \n",
    "        # --- Adjusted Interval Plot ---\n",
    "        adjusted_sleep_stage_interval_s = None\n",
    "        print(f\"\\n--- Adjusted Sleep Stage Interval Calculation Method ---\")\n",
    "        if SESSION_END_ISO_STR and valid_start_time:\n",
    "            try:\n",
    "                session_end_dt = datetime.fromisoformat(SESSION_END_ISO_STR)\n",
    "                actual_total_duration_s = (session_end_dt - session_start_dt).total_seconds()\n",
    "                if len(sleep_stages_all) > 0 and actual_total_duration_s > 0:\n",
    "                    adjusted_sleep_stage_interval_s = actual_total_duration_s / len(sleep_stages_all)\n",
    "                    print(f\"Using session start/end times for interval calculation.\")\n",
    "                    print(f\"Session Start: {session_start_iso_str}, Session End: {SESSION_END_ISO_STR}\")\n",
    "                    print(f\"Calculated total duration from timestamps: {actual_total_duration_s:.2f} seconds\")\n",
    "                    print(f\"Number of sleep stages: {len(sleep_stages_all)}\")\n",
    "                else:\n",
    "                    print(\"Could not calculate interval from session times (zero stages or non-positive duration).\")\n",
    "            except ValueError:\n",
    "                print(f\"Error: SESSION_END_ISO_STR '{SESSION_END_ISO_STR}' is not a valid ISO format. Cannot calculate interval from session end.\")\n",
    "        else:\n",
    "            print(\"SESSION_END_ISO_STR not provided or session_start_iso invalid. Attempting fallback calculation.\")\n",
    "\n",
    "        if adjusted_sleep_stage_interval_s is None and data and hasattr(data, 'get'): # Fallback if not calculated from timestamps\n",
    "            raw_eeg_data_info = data.get(\"DATA\", {}).get(\"RAW\", {}).get(\"EEG\")\n",
    "            if raw_eeg_data_info is not None and hasattr(raw_eeg_data_info, 'shape') and raw_eeg_data_info.shape[0] > 0:\n",
    "                total_raw_eeg_samples = raw_eeg_data_info.shape[0]\n",
    "                FS_FOR_ADJUSTMENT = 125.0  \n",
    "                if len(sleep_stages_all) > 0 and FS_FOR_ADJUSTMENT > 0:\n",
    "                    eeg_based_total_duration_s = total_raw_eeg_samples / FS_FOR_ADJUSTMENT\n",
    "                    adjusted_sleep_stage_interval_s = eeg_based_total_duration_s / len(sleep_stages_all)\n",
    "                    print(f\"Using EEG samples for interval calculation (fallback).\")\n",
    "                    print(f\"Total raw EEG samples (from load_experiment): {total_raw_eeg_samples}\")\n",
    "                    print(f\"Assumed sampling frequency for adjustment: {FS_FOR_ADJUSTMENT} Hz\")\n",
    "                    print(f\"Calculated total duration of EEG data: {eeg_based_total_duration_s:.2f} seconds\")\n",
    "                    print(f\"Number of sleep stages: {len(sleep_stages_all)}\")\n",
    "                else:\n",
    "                    print(\"Could not calculate interval from EEG samples (zero stages or non-positive FS).\")\n",
    "            else:\n",
    "                print(\"Could not retrieve valid EEG data shape from load_experiment data for fallback calculation.\")\n",
    "        elif adjusted_sleep_stage_interval_s is None:\n",
    "             print(\"Data from load_experiment not available for fallback calculation.\")\n",
    "\n",
    "        if adjusted_sleep_stage_interval_s is not None and adjusted_sleep_stage_interval_s > 0:\n",
    "            print(f\"ADJUSTED SLEEP STAGE INTERVAL: {adjusted_sleep_stage_interval_s:.2f} seconds/stage\")\n",
    "            sleep_stage_time_axis_full_adj_s = np.arange(len(sleep_stages_all)) * adjusted_sleep_stage_interval_s\n",
    "\n",
    "            # Apply Slicing for Adjusted Plot\n",
    "            slice_indices_adj = np.ones(len(sleep_stages_all), dtype=bool)\n",
    "            xlim_start_adj = PLOT_SLICE_START_S if PLOT_SLICE_START_S is not None else (sleep_stage_time_axis_full_adj_s[0] if len(sleep_stage_time_axis_full_adj_s) > 0 else 0)\n",
    "            xlim_end_adj = PLOT_SLICE_END_S if PLOT_SLICE_END_S is not None else (sleep_stage_time_axis_full_adj_s[-1] + adjusted_sleep_stage_interval_s if len(sleep_stage_time_axis_full_adj_s) > 0 else 0)\n",
    "\n",
    "            if PLOT_SLICE_START_S is not None:\n",
    "                slice_indices_adj &= (sleep_stage_time_axis_full_adj_s + adjusted_sleep_stage_interval_s > PLOT_SLICE_START_S)\n",
    "            if PLOT_SLICE_END_S is not None:\n",
    "                slice_indices_adj &= (sleep_stage_time_axis_full_adj_s < PLOT_SLICE_END_S)\n",
    "                \n",
    "            sleep_stages_adj_plot = sleep_stages_all[slice_indices_adj]\n",
    "            sleep_stage_time_axis_adj_plot_s = sleep_stage_time_axis_full_adj_s[slice_indices_adj]\n",
    "\n",
    "            if len(sleep_stages_adj_plot) == 0:\n",
    "                print(f\"No sleep stage data in the selected slice for the adjusted plot: {PLOT_SLICE_START_S}s - {PLOT_SLICE_END_S}s.\")\n",
    "            else:\n",
    "                print(\"\\n--- Generating Adjusted Plot ---\")\n",
    "                plt.figure(figsize=(16, 6))\n",
    "                \n",
    "                for stage_val in unique_stages_in_data: \n",
    "                    if stage_val in sleep_stage_labels:\n",
    "                         plt.bar(0, 0, width=0, color=sleep_stage_colors.get(stage_val, 'black'), label=f\"Stage: {sleep_stage_labels[stage_val]}\")\n",
    "\n",
    "                for i, stage in enumerate(sleep_stages_adj_plot):\n",
    "                    start_time = sleep_stage_time_axis_adj_plot_s[i]\n",
    "                    bar_width = adjusted_sleep_stage_interval_s\n",
    "\n",
    "                    effective_bar_start = start_time\n",
    "                    if PLOT_SLICE_START_S is not None and start_time < PLOT_SLICE_START_S:\n",
    "                        effective_bar_start = PLOT_SLICE_START_S\n",
    "                        bar_width = (start_time + adjusted_sleep_stage_interval_s) - PLOT_SLICE_START_S\n",
    "                    if PLOT_SLICE_END_S is not None and start_time + adjusted_sleep_stage_interval_s > PLOT_SLICE_END_S:\n",
    "                        if effective_bar_start == PLOT_SLICE_START_S:\n",
    "                             bar_width = PLOT_SLICE_END_S - PLOT_SLICE_START_S if start_time < PLOT_SLICE_START_S else PLOT_SLICE_END_S - start_time\n",
    "                        else:\n",
    "                            bar_width = PLOT_SLICE_END_S - start_time\n",
    "                    \n",
    "                    if bar_width <= 0: continue\n",
    "                    \n",
    "                    color = sleep_stage_colors.get(stage, 'black')\n",
    "                    plt.bar(effective_bar_start, bottom=stage-0.4, height=0.8, width=bar_width,\n",
    "                            color=color, align='edge', alpha=0.7)\n",
    "                \n",
    "                current_ylim_adj = plt.ylim() \n",
    "\n",
    "                plotted_cues_adj = False\n",
    "                plotted_initiations_adj = False\n",
    "                if valid_start_time and audio_cue_timestamps_abs is not None and hasattr(audio_cue_timestamps_abs, '__len__') and len(audio_cue_timestamps_abs) > 0:\n",
    "                    cue_slice_indices_adj = (relative_audio_cue_times_s_all >= xlim_start_adj) & (relative_audio_cue_times_s_all <= xlim_end_adj)\n",
    "                    relative_audio_cue_times_s_adj_plot = relative_audio_cue_times_s_all[cue_slice_indices_adj]\n",
    "\n",
    "                    if len(relative_audio_cue_times_s_adj_plot) > 0:\n",
    "                        plt.vlines(relative_audio_cue_times_s_adj_plot, ymin=current_ylim_adj[0], ymax=current_ylim_adj[1],\n",
    "                                   colors='red', linestyles='dashed', label='Audio Cue Fired', zorder=5, alpha=0.8)\n",
    "                        plotted_cues_adj = True\n",
    "\n",
    "                    initiation_slice_indices_adj = (np.array(audio_cue_initiation_times_s_all) >= xlim_start_adj) & (np.array(audio_cue_initiation_times_s_all) <= xlim_end_adj)\n",
    "                    audio_cue_initiation_times_s_adj_plot = np.array(audio_cue_initiation_times_s_all)[initiation_slice_indices_adj]\n",
    "                    \n",
    "                    if len(audio_cue_initiation_times_s_adj_plot) > 0:\n",
    "                        plt.vlines(audio_cue_initiation_times_s_adj_plot, ymin=current_ylim_adj[0], ymax=current_ylim_adj[1],\n",
    "                                   colors='green', linestyles='dotted', label='Audio Cue Sequence Initiated', zorder=4, alpha=0.9)\n",
    "                        plotted_initiations_adj = True\n",
    "                \n",
    "                # plt.title(f\"Sleep Stages & Cues (Adjusted Interval: {adjusted_sleep_stage_interval_s:.2f}s/stage)\")\n",
    "                plt.title(\n",
    "                    f\"Sleep Stages & Cues\")\n",
    "                plt.xlabel(f\"Time from Session Start (seconds)\")\n",
    "                plt.ylabel(\"Sleep Stage\")\n",
    "                plt.yticks([-1, 0, 1, 2, 3], ['Undefined', 'Awake', 'Light', 'Deep', 'REM'])\n",
    "                plt.legend(loc='upper right')\n",
    "                plt.grid(True, axis='x')\n",
    "                plt.ylim(current_ylim_adj) \n",
    "                plt.xlim(xlim_start_adj, xlim_end_adj)\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "                \n",
    "                if valid_start_time and audio_cue_timestamps_abs is not None:\n",
    "                    if hasattr(audio_cue_timestamps_abs, '__len__') and len(audio_cue_timestamps_abs) > 0:\n",
    "                        if plotted_cues_adj: \n",
    "                             print(f\"Adjusted Plot - Audio Cues Fired (seconds from session start, PLOTTED SLICE): {np.round(relative_audio_cue_times_s_adj_plot, 2)}\")\n",
    "                        if plotted_initiations_adj: \n",
    "                            print(f\"Adjusted Plot - Audio Cue Sequence Initiations (seconds from session start, PLOTTED SLICE): {np.round(audio_cue_initiation_times_s_adj_plot, 2)}\")\n",
    "                    elif not plotted_cues_adj and not plotted_initiations_adj:\n",
    "                        print(\"\\nAdjusted Plot - Audio cue timestamp data found but was empty or all cues/initiations outside selected slice. No cues plotted.\")\n",
    "        else:\n",
    "            print(\"\\nAdjusted Plot: Could not determine a valid adjusted sleep stage interval. Plotting skipped.\")\n",
    "\n",
    "    elif sleep_stages_all is not None: \n",
    "        print(\"Sleep stage data in metadata is empty. Cannot plot.\")\n",
    "    else: \n",
    "        print(\"Sleep stage data ('array__sleep_stage') not found in metadata scores. Cannot plot sleep stages and cues from metadata.\")\n",
    "\n",
    "elif not metadata:\n",
    "    print(\"Metadata object not loaded. Cannot process scores or cues.\")\n",
    "elif 'scores' not in metadata :\n",
    "    print(\"Key 'scores' not found in metadata.\")\n",
    "elif 'session_start_iso' not in metadata :\n",
    "    print(\"Key 'session_start_iso' not found in metadata (needed for plotting audio cues relative to session start).\")\n",
    "\n",
    "# Fallback plotting does not currently support slicing, it will show the full data from Frenz toolkit.\n",
    "if not (metadata and 'scores' in metadata and metadata['scores'].item().get(\"array__sleep_stage\") is not None and \\\n",
    "    len(metadata['scores'].item().get(\"array__sleep_stage\")) > 0 and 'session_start_iso' in metadata) :\n",
    "    \n",
    "    print(\"\\n--- Attempting Fallback: Load Sleep Stages with Frenz Toolkit ---\")\n",
    "    if SESSION_PATH and os.path.isdir(SESSION_PATH):\n",
    "        session_subfolders = [d for d in os.listdir(SESSION_PATH) if os.path.isdir(os.path.join(SESSION_PATH, d))]\n",
    "        \n",
    "        if session_subfolders:\n",
    "            session_subfolder_for_frenz = os.path.join(SESSION_PATH, session_subfolders[0])\n",
    "            print(f\"Attempting to load Frenz experiment data from subfolder: {session_subfolder_for_frenz}\")\n",
    "            \n",
    "            try:\n",
    "                session_data = load_experiment(session_subfolder_for_frenz)\n",
    "                sleep_stage_list = session_data.get(\"SCORE\", {}).get(\"array__sleep_stage\")\n",
    "\n",
    "                if sleep_stage_list is not None and len(sleep_stage_list) > 0:\n",
    "                    plt.figure(figsize=(12, 3))\n",
    "                    SLEEP_STAGE_INTERVAL_S_FRENZ = 30.0 \n",
    "                    score_time_axis = np.arange(len(sleep_stage_list)) * SLEEP_STAGE_INTERVAL_S_FRENZ\n",
    "                    for i, stage in enumerate(sleep_stage_list):\n",
    "                        start_time = score_time_axis[i]\n",
    "                        color = sleep_stage_colors.get(stage, 'black') \n",
    "                        plt.bar(start_time, bottom=stage-0.4, height=0.8, width=SLEEP_STAGE_INTERVAL_S_FRENZ, \n",
    "                                color=color, align='edge', alpha=0.7)\n",
    "\n",
    "                    plt.title(\"Sleep Stages Over Session (from Frenz Toolkit data)\")\n",
    "                    plt.xlabel(f\"Time (seconds)\")\n",
    "                    plt.ylabel(\"Sleep Stage\")\n",
    "                    plt.yticks([-1, 0, 1, 2, 3], ['Undefined', 'Awake', 'Light', 'Deep', 'REM'])\n",
    "                    unique_fallback_stages = np.unique(sleep_stage_list)\n",
    "                    for stage_val in unique_fallback_stages:\n",
    "                        if stage_val in sleep_stage_labels:\n",
    "                            plt.bar(0, 0, width=0, color=sleep_stage_colors.get(stage_val, 'black'), label=f\"Stage: {sleep_stage_labels[stage_val]}\")\n",
    "                    plt.legend(loc='upper right')\n",
    "                    plt.grid(True, axis='x')\n",
    "                    plt.show()\n",
    "                else:\n",
    "                    print(\"No sleep stage data available in Frenz Toolkit session data or data format unexpected.\")\n",
    "            except FileNotFoundError:\n",
    "                print(f\"Frenz experiment data not found in expected subfolder: {session_subfolder_for_frenz}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading or plotting data using Frenz Toolkit: {e}\")\n",
    "        else:\n",
    "            print(f\"No subdirectories found in {SESSION_PATH} to attempt loading Frenz experiment data from.\")\n",
    "    else:\n",
    "        print(\"SESSION_PATH not set, cannot attempt Frenz Toolkit fallback.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
