{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# --- Configuration ---\n",
    "# Make paths relative to WORKSPACE_ROOT\n",
    "\n",
    "# Determine paths programmatically instead of hardcoding\n",
    "WORKSPACE_ROOT = os.getcwd()\n",
    "\n",
    "# Define experiment details\n",
    "SAMPLE_DATA_FOLDER = \"sample_data\"\n",
    "EXPERIMENT_ID = \"E23B6B24FX14_1743611361000\"\n",
    "\n",
    "# Construct file paths\n",
    "edf_file_path = os.path.join(WORKSPACE_ROOT, SAMPLE_DATA_FOLDER, EXPERIMENT_ID, f\"{EXPERIMENT_ID}.edf\")\n",
    "csv_file_path = os.path.join(WORKSPACE_ROOT, SAMPLE_DATA_FOLDER, EXPERIMENT_ID, f\"{EXPERIMENT_ID}.csv\")\n",
    "\n",
    "# Print workspace root for verification\n",
    "print(f\"Using workspace root: {WORKSPACE_ROOT}\")\n",
    "\n",
    "# Based on the internal definition in predict_alertness_ema\n",
    "CHANNELS_FRONTAL = ['LF-FpZ', 'OTE_L-FpZ', 'RF-FpZ', 'OTE_R-FpZ']\n",
    "\n",
    "print(f\"Using CHANNELS_FRONTAL for predict_alertness_ema: {CHANNELS_FRONTAL}\")\n",
    "\n",
    "# --- Load Sleep stages (only the 'Sleep stage' column is needed now) ---\n",
    "print(f\"Loading sleep stages from: {csv_file_path}\")\n",
    "stages_df = pd.read_csv(csv_file_path, usecols=['Sleep stage'])\n",
    "\n",
    "# --- Load EDF Data ---\n",
    "print(f\"Loading EDF data from: {edf_file_path}\")\n",
    "raw_eeg_full_channels = mne.io.read_raw_edf(edf_file_path, preload=True, verbose='INFO')\n",
    "\n",
    "# Pick and reorder the necessary channels.\n",
    "# The `ordered=True` flag ensures they are in the order of CHANNELS_FRONTAL.\n",
    "# If any channel in CHANNELS_FRONTAL is not found, pick_channels will raise a ValueError.\n",
    "try:\n",
    "    raw_eeg = raw_eeg_full_channels.copy().pick_channels(CHANNELS_FRONTAL, ordered=True)\n",
    "    print(f\"Successfully picked and ordered channels: {raw_eeg.ch_names}\")\n",
    "except ValueError as e:\n",
    "    print(f\"Critical Error: Could not pick or order the required channels ({CHANNELS_FRONTAL}). {e}\")\n",
    "    print(\"Please ensure the EDF file contains these channels or adjust CHANNELS_FRONTAL if the model expects different ones.\")\n",
    "    raise # Stop execution if essential channels are missing\n",
    "\n",
    "eeg_data = raw_eeg.get_data() # Shape: (len(CHANNELS_FRONTAL), n_samples)\n",
    "FS_ORIGINAL = int(raw_eeg.info['sfreq'])\n",
    "FS_TARGET = 125\n",
    "\n",
    "# session_start_time_utc is still useful for metadata, even if not for stage alignment\n",
    "if raw_eeg.info['meas_date']:\n",
    "    session_start_time_utc_eeg = raw_eeg.info['meas_date'] \n",
    "else:\n",
    "    try:\n",
    "        filename = os.path.basename(edf_file_path)\n",
    "        timestamp_ms = int(filename.split('_')[1])\n",
    "        session_start_time_utc_eeg = datetime.fromtimestamp(timestamp_ms / 1000, timezone.utc) \n",
    "        print(f\"Inferred session start time from filename: {session_start_time_utc_eeg}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not infer session start time from filename ({e}), setting to now (UTC).\")\n",
    "        session_start_time_utc_eeg = datetime.now(timezone.utc)\n",
    "\n",
    "if session_start_time_utc_eeg.tzinfo is None:\n",
    "    print(\"Warning: session_start_time_utc was naive, localizing to UTC.\")\n",
    "    session_start_time_utc_eeg = session_start_time_utc_eeg.replace(tzinfo=timezone.utc)\n",
    "elif session_start_time_utc_eeg.tzinfo != timezone.utc:\n",
    "    print(f\"Warning: session_start_time_utc was {session_start_time_utc_eeg.tzinfo}, converting to UTC.\")\n",
    "    session_start_time_utc_eeg = session_start_time_utc_eeg.astimezone(timezone.utc)\n",
    "\n",
    "print(f\"EEG session start time (UTC): {session_start_time_utc_eeg}\")\n",
    "print(f\"Original sampling frequency: {FS_ORIGINAL} Hz\")\n",
    "\n",
    "# --- Prepare EEG Data ---\n",
    "EEG_CHANNELS_TO_USE = raw_eeg.ch_names\n",
    "print(f\"Using available EEG channels from EDF: {EEG_CHANNELS_TO_USE}\")\n",
    "raw_eeg = raw_eeg.copy().pick_channels(EEG_CHANNELS_TO_USE, ordered=False)\n",
    "eeg_data = raw_eeg.get_data() \n",
    "\n",
    "print(f\"EEG data loaded. Shape: {eeg_data.shape}, Sampling Rate: {FS_ORIGINAL} Hz\")\n",
    "print(f\"EEG session start time (UTC): {session_start_time_utc_eeg.isoformat()}\")\n",
    "\n",
    "eog_data = None \n",
    "print(\"EOG data processing and derivation has been removed for this simulation.\")\n",
    "\n",
    "# --- Print final data shapes and info ---\n",
    "print(\"Data loading and initial preparation complete.\")\n",
    "print(f\"EEG data shape: {eeg_data.shape}\")\n",
    "print(\"EOG data: Not used in this simulation.\")\n",
    "print(f\"Sampling Frequency (FS_ORIGINAL): {FS_ORIGINAL} Hz\")\n",
    "\n",
    "# --- Load Sleep stages Data ---\n",
    "stages_df = pd.read_csv(csv_file_path, comment='#')\n",
    "# Assuming the first column is 'Time' (ISO format or Unix timestamp) and the second is 'Sleep stage'\n",
    "stages_df.columns = ['Timestamp', 'Sleep stage'] # Ensure correct column names\n",
    "\n",
    "# Convert 'Time' to datetime objects and then to seconds from the EEG session start\n",
    "def parse_time(time_val):\n",
    "    if isinstance(time_val, str):\n",
    "        return datetime.fromisoformat(time_val.replace(\"Z\", \"+00:00\"))\n",
    "    elif isinstance(time_val, (int, float)): # Assuming Unix timestamp if numeric\n",
    "        return datetime.fromtimestamp(time_val, tz=timezone.utc)\n",
    "    return None\n",
    "\n",
    "stages_df['datetime_utc'] = stages_df['Timestamp'].apply(parse_time)\n",
    "stages_df = stages_df.dropna(subset=['datetime_utc']) # Remove rows where time parsing failed\n",
    "stages_df = stages_df.sort_values(by='datetime_utc') # Ensure chronological order\n",
    "\n",
    "# Use EEG start time as the reference for sleep stage timings\n",
    "session_start_time_utc_stages = stages_df['datetime_utc'].min()\n",
    "# Align stages_df 'seconds_from_session_start' with the EEG data's session_start_time_utc_eeg\n",
    "stages_df['seconds_from_session_start'] = (stages_df['datetime_utc'] - session_start_time_utc_eeg).dt.total_seconds()\n",
    "\n",
    "# Ensure 'seconds_from_session_start' are non-negative (stages can't start before EEG)\n",
    "stages_df = stages_df[stages_df['seconds_from_session_start'] >= 0]\n",
    "\n",
    "\n",
    "print(f\"Sleep stages loaded. Number of entries: {len(stages_df)}\")\n",
    "if not stages_df.empty:\n",
    "    print(f\"First sleep stage entry: Time {stages_df.iloc[0]['datetime_utc'].isoformat()}, Stage {stages_df.iloc[0]['Sleep stage']}, Seconds from EEG start: {stages_df.iloc[0]['seconds_from_session_start']:.2f}\")\n",
    "    print(f\"Last sleep stage entry: Time {stages_df.iloc[-1]['datetime_utc'].isoformat()}, Stage {stages_df.iloc[-1]['Sleep stage']}, Seconds from EEG start: {stages_df.iloc[-1]['seconds_from_session_start']:.2f}\")\n",
    "else:\n",
    "    print(\"Warning: Sleep stages DataFrame is empty after processing.\")\n",
    "\n",
    "# Set the overall session start time for the simulation to be the EEG start time.\n",
    "session_start_time_utc = session_start_time_utc_eeg\n",
    "print(f\"Simulation session start time (UTC) set to EEG start: {session_start_time_utc.isoformat()}\")\n",
    "\n",
    "# Simulation duration based on EEG data length\n",
    "total_samples_eeg = eeg_data.shape[1]\n",
    "simulation_duration_seconds = total_samples_eeg / FS_ORIGINAL\n",
    "print(f\"Total EEG samples: {total_samples_eeg}, Simulation duration: {simulation_duration_seconds:.2f} seconds\")\n",
    "\n",
    "# EOG data loading and processing is removed as per user request.\n",
    "eog_data = None\n",
    "fs_eog = None\n",
    "print(\"EOG data processing has been skipped.\")\n",
    "\n",
    "# Ensure stages_df is available for the next cells\n",
    "print(f\"Stages DF head:\\\\n{stages_df.head()}\")\n",
    "\n",
    "# --- Load EEG Data ---\n",
    "raw_eeg = mne.io.read_raw_edf(edf_file_path, preload=True, verbose=False)\n",
    "# Or adjust channel names\n",
    "eeg_data = raw_eeg.get_data(picks=['LF-FpZ', 'OTE_L-FpZ', 'RF-FpZ', 'OTE_R-FpZ'])\n",
    "fs_original = int(raw_eeg.info['sfreq'])\n",
    "session_start_time_utc_eeg = raw_eeg.info['meas_date']\n",
    "if session_start_time_utc_eeg.tzinfo is None:\n",
    "    session_start_time_utc_eeg = session_start_time_utc_eeg.replace(tzinfo=timezone.utc)\n",
    "\n",
    "print(f\"EEG data loaded. Shape: {eeg_data.shape}, Sampling Rate: {fs_original} Hz\")\n",
    "print(f\"EEG session start time (UTC): {session_start_time_utc_eeg.isoformat()}\")\n",
    "\n",
    "# --- Load Sleep stages Data & Generate Timestamps ---\n",
    "# Load only the 'Sleep stage' column, or if 'Time' is needed for other reasons, load it but don't use for primary timing.\n",
    "try:\n",
    "    # Attempt to read, expecting at least 'Sleep stage'. If 'Time' exists, it's fine.\n",
    "    stages_df_raw = pd.read_csv(csv_file_path, comment='#')\n",
    "    if 'Sleep stage' not in stages_df_raw.columns:\n",
    "        # If 'Sleep stage' is not a header, assume it's the second column (index 1)\n",
    "        # and the first column (index 0) might be original times (which we will ignore for timing)\n",
    "        stages_df_raw = pd.read_csv(csv_file_path, comment='#', header=None)\n",
    "        # Try to infer sensible column names if no header\n",
    "        if stages_df_raw.shape[1] > 1:\n",
    "            stages_df_raw.columns = [f'Column{i}' for i in range(stages_df_raw.shape[1])]\n",
    "            # Assume the relevant stage data is in a column named 'Sleep stage' or likely the second one\n",
    "            # This part might need adjustment based on actual CSV structure without headers\n",
    "            if 'Sleep stage' in stages_df_raw.columns:\n",
    "                stages_df = pd.DataFrame(stages_df_raw['Sleep stage'])\n",
    "            elif stages_df_raw.shape[1] >= 2: # Take second column as sleep stage\n",
    "                stages_df = pd.DataFrame(stages_df_raw.iloc[:, 1])\n",
    "                stages_df.columns = ['Sleep stage']\n",
    "            else: # Single column CSV, assume it's sleep stages\n",
    "                stages_df = pd.DataFrame(stages_df_raw.iloc[:, 0])\n",
    "                stages_df.columns = ['Sleep stage']\n",
    "        else: # Single column CSV\n",
    "            stages_df = pd.DataFrame(stages_df_raw.iloc[:, 0])\n",
    "            stages_df.columns = ['Sleep stage']\n",
    "    else:\n",
    "        stages_df = pd.DataFrame(stages_df_raw['Sleep stage'])\n",
    "except Exception as e:\n",
    "    print(f\"Error reading or processing CSV: {e}. Please check CSV format.\")\n",
    "    stages_df = pd.DataFrame(columns=['Sleep stage']) # Create empty df to avoid downstream errors\n",
    "\n",
    "stages_df = stages_df[stages_df['Sleep stage'] != 'UNKNOWN'] # Filter out UNKNOWN stages\n",
    "stages_df = stages_df.reset_index(drop=True) # Ensure clean index\n",
    "\n",
    "# Generate datetime_utc and seconds_from_session_start assuming 30s intervals\n",
    "num_stages = len(stages_df)\n",
    "stage_datetimes_utc = [session_start_time_utc_eeg + timedelta(seconds=i * 30) for i in range(num_stages)]\n",
    "stages_df['datetime_utc'] = stage_datetimes_utc\n",
    "stages_df['seconds_from_session_start'] = np.arange(0, num_stages * 30, 30)\n",
    "\n",
    "print(f\"Sleep stages processed. Number of entries: {len(stages_df)}\")\n",
    "if not stages_df.empty:\n",
    "    print(f\"First generated sleep stage entry: Time {stages_df.iloc[0]['datetime_utc'].isoformat()}, Stage {stages_df.iloc[0]['Sleep stage']}, Seconds from EEG start: {stages_df.iloc[0]['seconds_from_session_start']:.2f}\")\n",
    "    print(f\"Last generated sleep stage entry: Time {stages_df.iloc[-1]['datetime_utc'].isoformat()}, Stage {stages_df.iloc[-1]['Sleep stage']}, Seconds from EEG start: {stages_df.iloc[-1]['seconds_from_session_start']:.2f}\")\n",
    "else:\n",
    "    print(\"Warning: Sleep stages DataFrame is empty after processing.\")\n",
    "\n",
    "# Set the overall session start time for the simulation to be the EEG start time.\n",
    "session_start_time_utc = session_start_time_utc_eeg\n",
    "print(f\"Simulation session start time (UTC) set to EEG start: {session_start_time_utc.isoformat()}\")\n",
    "\n",
    "# Simulation duration based on EEG data length\n",
    "total_samples_eeg = eeg_data.shape[1]\n",
    "simulation_duration_seconds = total_samples_eeg / fs_original\n",
    "print(f\"Total EEG samples: {total_samples_eeg}, Simulation duration: {simulation_duration_seconds:.2f} seconds\")\n",
    "\n",
    "\n",
    "print(f\"Stages DF head:\\\\n{stages_df.head()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import sys # Added sys import\n",
    "import os # Added os import\n",
    "\n",
    "# Add workspace root to sys.path\n",
    "\n",
    "if WORKSPACE_ROOT not in sys.path:\n",
    "    sys.path.insert(0, WORKSPACE_ROOT)\n",
    "\n",
    "from dl_alertness_detection import predict_alertness_ema # Import actual function\n",
    "from app.main import needed_len # Import needed_len\n",
    "\n",
    "# --- Simulation Constants ---\n",
    "REM_SLEEP_STAGE_VALUE = \"REM\"\n",
    "MAX_SUCCESSIVE_REM_CUES = 2\n",
    "REM_AUDIO_CUE_INTERVAL_SECONDS = 10  # Minimum interval between REM cue sequences\n",
    "ALERTNESS_THRESHOLD_FOR_ACTION = 0.6 # Example threshold\n",
    "SECONDS_PER_WINDOW = 1 # Process data second by second\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def get_sleep_stage_at_time(current_sim_time_seconds, stages_df_param): \n",
    "    \"\"\" \n",
    "    Determines the sleep stage for the current_simulation_time_seconds.\n",
    "    Assumes stages_df_param has rows corresponding to 30-second epochs,\n",
    "    starting from t=0 of the simulation.\n",
    "    current_sim_time_seconds is relative to the start of the simulation (0 to simulation_duration_seconds)\n",
    "    \"\"\"\n",
    "    if stages_df_param.empty:\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "    stage_index = int(current_sim_time_seconds // 30)\n",
    "    sim_total_stages_count = len(stages_df_param) # Derive count internally\n",
    "\n",
    "    if 0 <= stage_index < sim_total_stages_count:\n",
    "        return stages_df_param['Sleep stage'].iloc[stage_index] # Assuming 'Sleep stage' is correct based on user's fix\n",
    "    elif stage_index >= sim_total_stages_count and sim_total_stages_count > 0:\n",
    "        # If current time exceeds the duration covered by stages, return the last known stage\n",
    "        return stages_df_param['Sleep stage'].iloc[-1] \n",
    "    else: # stage_index < 0 or sim_total_stages_count is 0\n",
    "        return \"UNKNOWN\"\n",
    "\n",
    "print(f\"Constants and helper functions defined. needed_len: {needed_len}\")\n",
    "\n",
    "# Cell 2: Helper Functions & Model/Parameter Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Attempt to import the specific model function and parameters\n",
    "from dl_alertness_detection import predict_alertness_ema\n",
    "needed_len = 18750 # 150s * 125 Hz\n",
    "\n",
    "# Helper to get sleep stage based on iteration (assuming 1 iteration = 1 second, stage changes every 30s)\n",
    "def get_sleep_stage_for_iteration(iteration_count, stages_df_param):\n",
    "    \"\"\"Retrieves the sleep stage for the current iteration.\"\"\"\n",
    "    if stages_df_param is None or stages_df_param.empty:\n",
    "        return \"Unknown\" # Or None, or raise error\n",
    "    \n",
    "    # Calculate which 30-second epoch this iteration falls into\n",
    "    # Iteration 0-29 -> epoch 0; 30-59 -> epoch 1, etc.\n",
    "    epoch_index = iteration_count // 30\n",
    "    \n",
    "    if epoch_index < len(stages_df_param):\n",
    "        return stages_df_param['Sleep stage'].iloc[epoch_index]\n",
    "    else:\n",
    "        # If simulation runs longer than recorded stages, return last known stage or a specific value\n",
    "        print(f\"Warning: Iteration {iteration_count} (epoch {epoch_index}) exceeds available sleep stages ({len(stages_df_param)}). Using last stage.\")\n",
    "        return stages_df_param['Sleep stage'].iloc[-1]\n",
    "\n",
    "print(\"Helper functions and model imports defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af62198",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_metadata_audio_cue_timestamps = []\n",
    "last_audio_cue_time = -float('inf')\n",
    "\n",
    "def fire_rem_audio_cues_sequence_sim(current_time_seconds):\n",
    "    \"\"\"Simulates firing audio cues and records their timestamps.\"\"\"\n",
    "    global last_audio_cue_time, sim_metadata_audio_cue_timestamps\n",
    "    \n",
    "    # print(f\"SIM AUDIO: Attempting to fire REM audio cue sequence at {current_time_seconds:.2f}s\")\n",
    "    for i in range(MAX_SUCCESSIVE_REM_CUES):\n",
    "        cue_initiation_time = current_time_seconds + (i * REM_AUDIO_CUE_INTERVAL_SECONDS)\n",
    "        # Check if enough time has passed since the *very last* cue of any sequence\n",
    "        # This is a simplified check for simulation; real app might have more complex state\n",
    "        if cue_initiation_time < last_audio_cue_time + REM_AUDIO_CUE_INTERVAL_SECONDS: \n",
    "            # This check is mostly to prevent overlapping print statements in rapid succession if called improperly\n",
    "            # The main loop's `is_in_rem_cycle` and `rem_audio_cues_fired_this_cycle` should prevent re-triggering too soon.\n",
    "            # print(f\"SIM AUDIO: Cue {i+1} at {cue_initiation_time:.2f}s would be too soon. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        sim_metadata_audio_cue_timestamps.append(cue_initiation_time)\n",
    "        print(f\"SIM AUDIO: Cue {i+1}/{MAX_SUCCESSIVE_REM_CUES} scheduled/fired at {cue_initiation_time:.2f}s (Simulated)\")\n",
    "        last_audio_cue_time = cue_initiation_time\n",
    "        \n",
    "        # In a real simulation, you might want to simulate the time passing for the cue duration\n",
    "        # For this, we just record the timestamp of when it *would* play.\n",
    "    return True # Indicates sequence was initiated\n",
    "\n",
    "print(\"Simulated audio cue function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample_poly\n",
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import scipy.signal\n",
    "import time # Added time import for verbosity\n",
    "\n",
    "# This cell should be run after the previous cells defining constants, helpers, and importing predict_alertness_ema\n",
    "\n",
    "def real_time_processing_simulation(\n",
    "    eeg_data_param,             # Shape (4, total_samples_at_125Hz)\n",
    "    original_sfreq_param,       # Should be 125 Hz as per user simplification\n",
    "    stages_df_param,            # DataFrame with 'Sleep stage' column\n",
    "    session_start_time_utc_param, # datetime object for recording start\n",
    "    total_duration_seconds_param, # Total duration of EEG data in seconds\n",
    "    predict_alertness_func,     # predict_alertness_ema\n",
    "    get_sleep_stage_func,       # get_sleep_stage_for_iteration\n",
    "    samples_for_model_window,   # This is `needed_len` (e.g., 18750 for 150s at 125Hz)\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates real-time processing of EEG data, simplified.\n",
    "    - Assumes eeg_data_param is sampled at 125 Hz.\n",
    "    - Iterates second by second.\n",
    "    - For predict_alertness_func, it provides a window of `samples_for_model_window`.\n",
    "    - Sleep stages are updated based on iteration count (every 30 iterations for 30s epochs).\n",
    "    \"\"\"\n",
    "    if original_sfreq_param != 125:\n",
    "        raise ValueError(f\"This simplified simulation expects original_sfreq_param to be 125 Hz, but got {original_sfreq_param}\")\n",
    "\n",
    "    print(f\"Starting simplified simulation. Total duration: {total_duration_seconds_param} seconds.\")\n",
    "    print(f\"EEG data shape: {eeg_data_param.shape}, sfreq: {original_sfreq_param} Hz\")\n",
    "    print(f\"Model requires a window of {samples_for_model_window} samples ({samples_for_model_window/original_sfreq_param}s at {original_sfreq_param}Hz).\")\n",
    "\n",
    "    SIMULATION_STEP_SECONDS = 1 # Iterating second by second\n",
    "    SAMPLES_PER_SECOND = int(original_sfreq_param) # Should be 125\n",
    "\n",
    "    timestamps_utc = []\n",
    "    sim_times_seconds = [] # This will be iteration count\n",
    "    sleep_stages_at_time = []\n",
    "    alertness_scores = []\n",
    "    audio_cue_timestamps_utc = []\n",
    "    \n",
    "    # Ensure session_start_time_utc_param is a datetime object (safeguard)\n",
    "    if isinstance(session_start_time_utc_param, str):\n",
    "        try:\n",
    "            session_start_time_utc_param = datetime.fromisoformat(session_start_time_utc_param.replace(\" \", \"T\"))\n",
    "        except ValueError:\n",
    "            session_start_time_utc_param = datetime.strptime(session_start_time_utc_param, \"%Y-%m-%d %H:%M:%S\")\n",
    "    elif not isinstance(session_start_time_utc_param, datetime):\n",
    "        raise TypeError(\"session_start_time_utc_param must be a datetime object or parsable string.\")\n",
    "\n",
    "    # The simulation runs for total_duration_seconds_param iterations (seconds).\n",
    "    # We can only start making predictions once we have enough data for the first model window.\n",
    "    # The iteration `i` represents the current second of the simulation.\n",
    "    # The data for the model at second `i` will be from `i - window_duration_seconds` to `i`.\n",
    "    \n",
    "    window_duration_seconds = samples_for_model_window / SAMPLES_PER_SECOND\n",
    "\n",
    "    for i in range(int(total_duration_seconds_param)):\n",
    "        current_sim_time_seconds = i \n",
    "        current_timestamp_utc = session_start_time_utc_param + timedelta(seconds=current_sim_time_seconds)\n",
    "        \n",
    "        timestamps_utc.append(current_timestamp_utc)\n",
    "        sim_times_seconds.append(current_sim_time_seconds)\n",
    "\n",
    "        # Get sleep stage based on iteration count\n",
    "        current_stage = get_sleep_stage_func(current_sim_time_seconds, stages_df_param)\n",
    "        sleep_stages_at_time.append(current_stage)\n",
    "\n",
    "        # Alertness Prediction\n",
    "        # We need `samples_for_model_window` ending at the current second (i).\n",
    "        # The start index for samples is (current_second * SAMPLES_PER_SECOND) - samples_for_model_window\n",
    "        # The end index is current_second * SAMPLES_PER_SECOND\n",
    "        \n",
    "        current_sample_end_point = (current_sim_time_seconds + 1) * SAMPLES_PER_SECOND # +1 because iteration `i` is the i-th second *elapsed*\n",
    "        current_sample_start_point = current_sample_end_point - samples_for_model_window\n",
    "\n",
    "        current_alertness_score = np.nan # Default\n",
    "        if current_sample_start_point >= 0:\n",
    "            # Extract the 4-channel data segment for the model\n",
    "            # eeg_data_param is (4, total_samples)\n",
    "            eeg_segment_for_model = eeg_data_param[:, current_sample_start_point:current_sample_end_point]\n",
    "            \n",
    "            if eeg_segment_for_model.shape[1] == samples_for_model_window:\n",
    "                try:\n",
    "                    # print(\"Passing in shape:\", eeg_segment_for_model.shape)\n",
    "                    current_alertness_score = predict_alertness_func(\n",
    "                        eeg_raw=eeg_segment_for_model\n",
    "                        # predict_alertness_ema uses hardcoded sfreq=125 internally for MNE object\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"Error during alertness prediction at sim_time {current_sim_time_seconds}s: {e}\")\n",
    "                    # current_alertness_score remains np.nan\n",
    "            else:\n",
    "                # This might happen at the very beginning if logic is slightly off, or end if total_samples isn't a perfect multiple.\n",
    "                print(f\"Warning: Could not extract full segment of {samples_for_model_window} samples at sim_time {current_sim_time_seconds}s. Got {eeg_segment_for_model.shape[1]}. Skipping prediction.\")\n",
    "        else:\n",
    "            # Not enough data accumulated yet for a full window\n",
    "            # print(f\"Sim_time {current_sim_time_seconds}s: Not enough data for first alertness window. Start point: {current_sample_start_point}\")\n",
    "            pass # current_alertness_score remains np.nan\n",
    "            \n",
    "        alertness_scores.append(current_alertness_score)\n",
    "\n",
    "        # Only fire audio cues if in REM sleep stage\n",
    "        if current_stage == REM_SLEEP_STAGE_VALUE and not np.isnan(current_alertness_score):\n",
    "            # Check if alertness score is above a threshold to trigger audio cues\n",
    "            if current_alertness_score < ALERTNESS_THRESHOLD_FOR_ACTION:\n",
    "                # Check if we are in a valid REM cycle to fire cues\n",
    "                if (current_sim_time_seconds - last_audio_cue_time) >= REM_AUDIO_CUE_INTERVAL_SECONDS:\n",
    "                    # Fire the audio cue sequence\n",
    "                    fire_rem_audio_cues_sequence_sim(current_sim_time_seconds)\n",
    "                    audio_cue_timestamps_utc.append(current_timestamp_utc)\n",
    "                else:\n",
    "                    print(f\"Skipping audio cue at {current_sim_time_seconds}s due to interval constraints.\")\n",
    "            else:\n",
    "                print(f\"Alertness score {current_alertness_score:.2f} at {current_sim_time_seconds}s is above threshold, not firing cues.\")\n",
    "        else:\n",
    "            print(f\"Current stage '{current_stage}' at {current_sim_time_seconds}s does not require audio cues.\")\n",
    "\n",
    "        \n",
    "        if current_sim_time_seconds > 0 and current_sim_time_seconds % 60 == 0: # Print progress every 60 seconds\n",
    "            print(f\"  Processed up to {current_sim_time_seconds}s / {int(total_duration_seconds_param)}s. Stage: {current_stage}, Alertness: {current_alertness_score if not np.isnan(current_alertness_score) else 'N/A'}\")\n",
    "\n",
    "    print(\"Simplified simulation finished.\")\n",
    "    return sim_times_seconds, timestamps_utc, sleep_stages_at_time, alertness_scores, audio_cue_timestamps_utc\n",
    "\n",
    "print(\"Simulation loop function `real_time_processing_simulation` defined and ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute the Simulation ---\n",
    "# This cell assumes all previous cells (data loading, helpers, simulation function) have been run.\n",
    "original_sfreq = 125 # As per user simplification\n",
    "total_duration_seconds = simulation_duration_seconds # From Cell 1\n",
    "print(\"Starting simulation execution...\")\n",
    "\n",
    "# Ensure global list for audio cues is initialized if not already by cell ffbe0495\n",
    "if 'sim_metadata_audio_cue_timestamps' not in globals():\n",
    "    sim_metadata_audio_cue_timestamps = []\n",
    "else:\n",
    "    sim_metadata_audio_cue_timestamps.clear() # Clear for a fresh run\n",
    "\n",
    "# Call the simulation function with variables loaded/defined in previous cells\n",
    "# These variables should be in the global notebook scope from executing Cell 1 (b00d3c33) and Cell 2 (921c860b)\n",
    "if 'eeg_data' in locals() and eeg_data is not None and \\\n",
    "   'original_sfreq' in locals() and original_sfreq == 125 and \\\n",
    "   'stages_df' in locals() and stages_df is not None and \\\n",
    "   'session_start_time_utc_eeg' in locals() and session_start_time_utc_eeg is not None and \\\n",
    "   'total_duration_seconds' in locals() and \\\n",
    "   'predict_alertness_ema' in locals() and \\\n",
    "   'get_sleep_stage_for_iteration' in locals() and \\\n",
    "   'needed_len' in locals() and \\\n",
    "   'fire_rem_audio_cues_sequence_sim' in locals():\n",
    "\n",
    "    print(\"All necessary variables seem to be loaded. Proceeding with simplified simulation execution.\")\n",
    "    print(f\"Using eeg_data with shape: {eeg_data.shape}\")\n",
    "    print(f\"Original sampling frequency: {original_sfreq} Hz\")\n",
    "    print(f\"Sleep stages DataFrame has {len(stages_df)} entries.\")\n",
    "    print(f\"Session start time: {session_start_time_utc_eeg}\")\n",
    "    print(f\"Total duration: {total_duration_seconds} seconds\")\n",
    "    print(f\"Model window requires: {needed_len} samples ({needed_len/original_sfreq}s)\")\n",
    "\n",
    "    # Reset alertness history for predict_alertness_ema if it exists from previous runs\n",
    "    if hasattr(predict_alertness_ema, \"alertness_history\"):\n",
    "        print(\"Resetting alertness_history in predict_alertness_ema.\")\n",
    "        predict_alertness_ema.alertness_history = []\n",
    "    \n",
    "    # Reset audio cue state if fire_rem_audio_cues_sequence_sim manages state internally\n",
    "    # (This depends on its implementation in Cell 3 - assuming it might need reset for multiple runs)\n",
    "    # For example, if it uses global or static-like variables for last_cue_time or successive_cues_count:\n",
    "    if 'last_successful_cue_time_sim' in globals():\n",
    "        print(\"Resetting last_successful_cue_time_sim for audio cue logic.\")\n",
    "        del globals()['last_successful_cue_time_sim']\n",
    "    if 'consecutive_rem_cues_triggered' in globals():\n",
    "        print(\"Resetting consecutive_rem_cues_triggered for audio cue logic.\")\n",
    "        del globals()['consecutive_rem_cues_triggered']\n",
    "\n",
    "\n",
    "    sim_results = real_time_processing_simulation(\n",
    "        eeg_data_param=eeg_data, \n",
    "        original_sfreq_param=original_sfreq, # Must be 125 Hz\n",
    "        stages_df_param=stages_df, \n",
    "        session_start_time_utc_param=session_start_time_utc_eeg,\n",
    "        total_duration_seconds_param=total_duration_seconds,\n",
    "        predict_alertness_func=predict_alertness_ema, \n",
    "        get_sleep_stage_func=get_sleep_stage_for_iteration, \n",
    "        samples_for_model_window=needed_len, # This is the 18750 samples for 150s window\n",
    "    )\n",
    "    sim_times, sim_timestamps_utc, sim_stages, sim_alertness, sim_cues_events = sim_results\n",
    "\n",
    "    print(\"\\nSimulation execution completed.\")\n",
    "    print(f\"Number of time points simulated: {len(sim_times)}\")\n",
    "    print(f\"Number of alertness scores generated: {len(sim_alertness)}\")\n",
    "    print(f\"Number of sleep stages recorded: {len(sim_stages)}\")\n",
    "    print(f\"Number of audio cue events: {len(sim_cues_events)}\")\n",
    "\n",
    "    # Basic check of results\n",
    "    if len(sim_times) > 0:\n",
    "        print(f\"  First sim time: {sim_times[0]}, Last sim time: {sim_times[-1]}\")\n",
    "        print(f\"  First alertness score: {sim_alertness[0] if sim_alertness else 'N/A'}\")\n",
    "        print(f\"  Last alertness score: {sim_alertness[-1] if sim_alertness else 'N/A'}\")\n",
    "        # Count valid alertness scores\n",
    "        valid_alertness_count = sum(1 for x in sim_alertness if not np.isnan(x))\n",
    "        print(f\"  Number of valid (non-NaN) alertness scores: {valid_alertness_count}\")\n",
    "    if len(sim_cues_events) > 0:\n",
    "        print(f\"  First audio cue event: {sim_cues_events[0]}\")\n",
    "\n",
    "else:\n",
    "    missing_vars = []\n",
    "    if 'eeg_data' not in locals() or eeg_data is None: missing_vars.append(\"eeg_data\")\n",
    "    if 'original_sfreq' not in locals() or original_sfreq != 125: missing_vars.append(\"original_sfreq (must be 125Hz)\")\n",
    "    if 'stages_df' not in locals() or stages_df is None: missing_vars.append(\"stages_df\")\n",
    "    if 'session_start_time_utc_eeg' not in locals() or session_start_time_utc_eeg is None: missing_vars.append(\"session_start_time_utc_eeg\")\n",
    "    if 'total_duration_seconds' not in locals() : missing_vars.append(\"total_duration_seconds\")\n",
    "    if 'predict_alertness_ema' not in locals(): missing_vars.append(\"predict_alertness_ema\")\n",
    "    if 'get_sleep_stage_for_iteration' not in locals(): missing_vars.append(\"get_sleep_stage_for_iteration\")\n",
    "    if 'needed_len' not in locals(): missing_vars.append(\"needed_len\")\n",
    "    if 'fire_rem_audio_cues_sequence_sim' not in locals(): missing_vars.append(\"fire_rem_audio_cues_sequence_sim\")\n",
    "    \n",
    "    print(f\"ERROR: Cannot run simulation. Essential data or functions are missing or misconfigured: {', '.join(missing_vars)}.\")\n",
    "    print(\"Please ensure Cell 1 (Data Loading), Cell 2 (Helpers), and Cell 3 (Audio Cues) are correctly defined and executed.\")\n",
    "    print(f\"  Current original_sfreq: {original_sfreq if 'original_sfreq' in locals() else 'Not defined'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot Simulation Results ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Check if simulation data exists in memory from Cell 5\n",
    "if 'sim_times' in locals() and \\\n",
    "   'sim_timestamps_utc' in locals() and \\\n",
    "   'sim_stages' in locals() and \\\n",
    "   'sim_alertness' in locals() and \\\n",
    "   'sim_cues_events' in locals():\n",
    "\n",
    "    print(\"Plotting simulation results directly from memory...\")\n",
    "\n",
    "    # Use the variables directly from the simulation output\n",
    "    simulation_times_seconds = np.array(sim_times)\n",
    "    # sim_timestamps_utc_loaded = sim_timestamps_utc # Already datetime objects\n",
    "    sleep_stages_loaded = sim_stages\n",
    "    alertness_scores_loaded = np.array(sim_alertness)\n",
    "    audio_cue_events_loaded = sim_cues_events # List of dicts or datetime objects\n",
    "\n",
    "    # --- Debug: Print unique stages from the loaded data ---\n",
    "    unique_stages_in_data = np.unique(sleep_stages_loaded)\n",
    "    print(f\"Unique sleep stages found in loaded data: {unique_stages_in_data}\")\n",
    "    # --- End Debug ---\n",
    "\n",
    "    # Define the mapping from stage strings to desired y-axis categories and plot values\n",
    "    # Y-axis categories and their desired order (top to bottom on plot)\n",
    "    # Wake (plot y=3), REM (plot y=2), Light (plot y=1), Deep (plot y=0)\n",
    "    y_plot_values_map = {\n",
    "        'Wake': 3,\n",
    "        'REM': 2,\n",
    "        'Light': 1, # Assuming 'Light' covers N1/N2\n",
    "        'Deep': 0   # Assuming 'Deep' covers N3\n",
    "        # Add other string mappings if present, e.g., 'N1', 'N2', 'N3' directly\n",
    "    }\n",
    "\n",
    "    mapped_sleep_stages_for_plot = []\n",
    "    for stage_str in sleep_stages_loaded:\n",
    "        if stage_str in y_plot_values_map:\n",
    "            mapped_sleep_stages_for_plot.append(y_plot_values_map[stage_str])\n",
    "        # Handle cases where stage strings might be slightly different (e.g., case sensitivity, or specific N1/N2/N3)\n",
    "        # Example: if your data has \"N1\" or \"N2\" for light sleep:\n",
    "        # elif stage_str == \"N1\" or stage_str == \"N2\":\n",
    "        #     mapped_sleep_stages_for_plot.append(y_plot_values_map['Light'])\n",
    "        else:\n",
    "            print(f\"Warning: Unmapped stage string '{stage_str}' found. Will be plotted as NaN.\")\n",
    "            mapped_sleep_stages_for_plot.append(np.nan) # Stage string not in our defined map\n",
    "    \n",
    "    # --- Debug: Print a sample of mapped stages ---\n",
    "    sample_mapped_stages = mapped_sleep_stages_for_plot[:20] # Print first 20 mapped values\n",
    "    num_nan_stages = np.sum(np.isnan(mapped_sleep_stages_for_plot))\n",
    "    print(f\"Sample of first 20 mapped_sleep_stages_for_plot: {sample_mapped_stages}\")\n",
    "    print(f\"Number of NaN values in mapped_sleep_stages_for_plot: {num_nan_stages} out of {len(mapped_sleep_stages_for_plot)}\")\n",
    "    # --- End Debug ---\n",
    "\n",
    "    fig, ax1 = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Sleep stage', color=color)\n",
    "    if not np.all(np.isnan(mapped_sleep_stages_for_plot)):\n",
    "        ax1.plot(simulation_times_seconds, mapped_sleep_stages_for_plot, color=color, linestyle='-', marker='.', label='Sleep stage')\n",
    "    else:\n",
    "        print(\"WARNING: All mapped sleep stages are NaN. Sleep stage line will not be plotted.\")\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    \n",
    "    # Set y-ticks and labels according to the keys in y_plot_values_map, ordered as desired\n",
    "    # The y_plot_values_map already defines the labels for the numeric y values.\n",
    "    # We want the labels on the y-axis to be 'Wake', 'REM', 'Light', 'Deep' from top to bottom.\n",
    "    # So, ticks should be [3, 2, 1, 0] and labels ['Wake', 'REM', 'Light', 'Deep']\n",
    "    sorted_y_labels = sorted(y_plot_values_map.items(), key=lambda item: item[1], reverse=True)\n",
    "    y_ticks = [item[1] for item in sorted_y_labels]\n",
    "    y_tick_labels = [item[0] for item in sorted_y_labels]\n",
    "\n",
    "    ax1.set_yticks(y_ticks)\n",
    "    ax1.set_yticklabels(y_tick_labels)\n",
    "    ax1.set_ylim(min(y_ticks) - 0.5, max(y_ticks) + 0.5) # Adjust ylim to give some padding\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('Alertness Score (EMA)', color=color)\n",
    "    ax2.plot(simulation_times_seconds, alertness_scores_loaded, color=color, linestyle='--', label='Alertness Score', alpha=0.7)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    ax2.set_ylim(0, 1)\n",
    "\n",
    "    if len(audio_cue_events_loaded) > 0:\n",
    "        for cue_time in audio_cue_events_loaded:\n",
    "            ax1.axvline(x=cue_time, color='tab:green', linestyle=':', linewidth=2, label='Audio Cue (REM)' if 'Audio Cue (REM)' not in [l.get_label() for l in ax1.lines] else \"\")\n",
    "    \n",
    "    plt.title('Simulation Results: Sleep stages, Alertness, and Audio Cues')\n",
    "    fig.tight_layout()\n",
    "    \n",
    "    lines, labels = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    if len(audio_cue_events_loaded) > 0 and not any('Audio Cue (REM)' in l for l in labels + labels2):\n",
    "        from matplotlib.lines import Line2D\n",
    "        proxy_line = Line2D([0], [0], linestyle=':', color='tab:green', linewidth=2, label='Audio Cue (REM)')\n",
    "        lines.append(proxy_line)\n",
    "        labels.append('Audio Cue (REM)')\n",
    "\n",
    "    ax2.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Simulation data not found in memory. Please run Cell 5 first to generate data.\")\n",
    "    print(\"Variables checked: sim_times, sim_timestamps_utc, sim_stages, sim_alertness, sim_cues_events\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
