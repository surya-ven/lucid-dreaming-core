{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681b1544",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# from scipy.signal import butter, filtfilt # No longer needed with simplified approach\n",
    "import os\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# --- Configuration ---\n",
    "# Make paths relative to WORKSPACE_ROOT\n",
    "\n",
    "# Determine paths programmatically instead of hardcoding\n",
    "WORKSPACE_ROOT = os.getcwd()\n",
    "\n",
    "# Define experiment details\n",
    "SAMPLE_DATA_FOLDER = \"sample_data\"\n",
    "EXPERIMENT_ID = \"E23B6B24FX14_1743611361000\"\n",
    "\n",
    "# Construct file paths\n",
    "edf_file_path = os.path.join(WORKSPACE_ROOT, SAMPLE_DATA_FOLDER, EXPERIMENT_ID, f\"{EXPERIMENT_ID}.edf\")\n",
    "csv_file_path = os.path.join(WORKSPACE_ROOT, SAMPLE_DATA_FOLDER, EXPERIMENT_ID, f\"{EXPERIMENT_ID}.csv\")\n",
    "\n",
    "# Print workspace root for verification\n",
    "print(f\"Using workspace root: {WORKSPACE_ROOT}\")\n",
    "\n",
    "FS_ORIGINAL = 0 \n",
    "\n",
    "# --- Load Sleep Stages (only the 'Sleep stage' column is needed now) ---\n",
    "print(f\"Loading sleep stages from: {csv_file_path}\")\n",
    "stages_df = pd.read_csv(csv_file_path, usecols=['Sleep stage'])\n",
    "\n",
    "# --- Load EDF Data ---\n",
    "print(f\"Loading EDF data from: {edf_file_path}\")\n",
    "raw = mne.io.read_raw_edf(edf_file_path, preload=True, verbose='INFO')\n",
    "FS_ORIGINAL = int(raw.info['sfreq'])\n",
    "\n",
    "# session_start_time_utc is still useful for metadata, even if not for stage alignment\n",
    "if raw.info['meas_date']:\n",
    "    session_start_time_utc = raw.info['meas_date'] \n",
    "else:\n",
    "    try:\n",
    "        filename = os.path.basename(edf_file_path)\n",
    "        timestamp_ms = int(filename.split('_')[1])\n",
    "        session_start_time_utc = datetime.fromtimestamp(timestamp_ms / 1000, timezone.utc) \n",
    "        print(f\"Inferred session start time from filename: {session_start_time_utc}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not infer session start time from filename ({e}), setting to now (UTC).\")\n",
    "        session_start_time_utc = datetime.now(timezone.utc)\n",
    "\n",
    "if session_start_time_utc.tzinfo is None:\n",
    "    print(\"Warning: session_start_time_utc was naive, localizing to UTC.\")\n",
    "    session_start_time_utc = session_start_time_utc.replace(tzinfo=timezone.utc)\n",
    "elif session_start_time_utc.tzinfo != timezone.utc:\n",
    "    print(f\"Warning: session_start_time_utc was {session_start_time_utc.tzinfo}, converting to UTC.\")\n",
    "    session_start_time_utc = session_start_time_utc.astimezone(timezone.utc)\n",
    "\n",
    "print(f\"Session start time (UTC): {session_start_time_utc}\")\n",
    "print(f\"Original sampling frequency: {FS_ORIGINAL} Hz\")\n",
    "\n",
    "# --- Prepare EEG Data ---\n",
    "EEG_CHANNELS_TO_USE = raw.ch_names\n",
    "print(f\"Using available EEG channels from EDF: {EEG_CHANNELS_TO_USE}\")\n",
    "raw_eeg = raw.copy().pick_channels(EEG_CHANNELS_TO_USE, ordered=False)\n",
    "eeg_data = raw_eeg.get_data() \n",
    "\n",
    "eog_data = None \n",
    "print(\"EOG data processing and derivation has been removed for this simulation.\")\n",
    "\n",
    "# --- Calculate total duration and sleep stage interval ---\n",
    "total_samples_eeg = eeg_data.shape[1]\n",
    "simulation_duration_seconds = total_samples_eeg / FS_ORIGINAL\n",
    "print(f\"Total samples in EEG data: {total_samples_eeg}\")\n",
    "print(f\"Calculated simulation duration: {simulation_duration_seconds:.2f} seconds\")\n",
    "\n",
    "n_sleep_stages_entries = len(stages_df)\n",
    "if n_sleep_stages_entries > 0:\n",
    "    sleep_stage_interval_seconds = simulation_duration_seconds / n_sleep_stages_entries\n",
    "    print(f\"Number of sleep stage entries in CSV: {n_sleep_stages_entries}\")\n",
    "    print(f\"Calculated sleep stage interval: {sleep_stage_interval_seconds:.2f} seconds per stage entry.\")\n",
    "else:\n",
    "    sleep_stage_interval_seconds = simulation_duration_seconds # Or some other default if no stages\n",
    "    print(\"Warning: No sleep stage entries found in CSV. Simulation will use a single stage or default.\")\n",
    "    # Optionally, create a default stage_df if it's empty to prevent errors later\n",
    "    if stages_df.empty:\n",
    "        stages_df = pd.DataFrame({'Sleep stage': [0]}) # Default to Wake\n",
    "        n_sleep_stages_entries = 1\n",
    "        print(\"Defaulting to a single 'Wake' stage for the entire duration.\")\n",
    "\n",
    "\n",
    "print(\"Data loading and initial preparation complete.\")\n",
    "print(f\"EEG data shape: {eeg_data.shape}\")\n",
    "print(\"EOG data: Not used in this simulation.\")\n",
    "print(f\"Sampling Frequency (FS_ORIGINAL): {FS_ORIGINAL} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fc0684",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone\n",
    "import scipy.signal\n",
    "import sys # Added sys import\n",
    "import os # Added os import\n",
    "\n",
    "# Add workspace root to sys.path\n",
    "\n",
    "if WORKSPACE_ROOT not in sys.path:\n",
    "    sys.path.insert(0, WORKSPACE_ROOT)\n",
    "\n",
    "from dl_alertness_detection import predict_alertness_ema # Import actual function\n",
    "from app.main import needed_len # Import needed_len\n",
    "\n",
    "# --- Simulation Constants ---\n",
    "FS_TARGET = 125  # Hz, target sampling frequency for processing\n",
    "REM_SLEEP_STAGE_VALUE = 3\n",
    "MAX_SUCCESSIVE_REM_CUES = 2\n",
    "REM_AUDIO_CUE_INTERVAL_SECONDS = 10  # Minimum interval between REM cue sequences\n",
    "ALERTNESS_THRESHOLD_FOR_ACTION = 0.6 # Example threshold\n",
    "ALERTNESS_EMA_ALPHA = 0.1 # For smoothing alertness, if we implement EMA here. The imported function has its own.\n",
    "SECONDS_PER_WINDOW = 1 # Process data second by second\n",
    "\n",
    "# --- Helper Functions ---\n",
    "def get_sleep_stage_at_time(current_sim_time_seconds, session_start_iso, stages_df, sim_stage_interval_seconds, sim_total_stages_count):\n",
    "    \"\"\"\n",
    "    Determines the sleep stage for a given simulation timestamp using fixed interval indexing.\n",
    "    \"\"\"\n",
    "    if stages_df is None or stages_df.empty:\n",
    "        print(\"Warning: Sleep stages DataFrame is empty or None.\")\n",
    "        return 0 # Default to awake or unknown if no data\n",
    "\n",
    "    # Calculate the index based on the current simulation time and the fixed interval\n",
    "    # current_sim_time_seconds is relative to the start of the simulation (0 to simulation_duration_seconds)\n",
    "    stage_index = int(current_sim_time_seconds // sim_stage_interval_seconds)\n",
    "\n",
    "    if 0 <= stage_index < sim_total_stages_count:\n",
    "        return stages_df['Sleep stage'].iloc[stage_index]\n",
    "    elif stage_index >= sim_total_stages_count:\n",
    "        # If current time exceeds the duration covered by stages, return the last known stage\n",
    "        print(f\"Warning: current_sim_time_seconds {current_sim_time_seconds} exceeds stage data coverage. Using last stage.\")\n",
    "        return stages_df['Sleep stage'].iloc[-1]\n",
    "    else:\n",
    "        # Should not happen if current_sim_time_seconds starts at 0\n",
    "        print(f\"Warning: Calculated stage_index {stage_index} is out of bounds. Defaulting to 0.\")\n",
    "        return 0\n",
    "\n",
    "# Placeholder for predict_alertness_ema_sim is now removed, we will use the imported one.\n",
    "\n",
    "print(f\"Constants and helper functions defined. needed_len: {needed_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af62198",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_metadata_audio_cue_timestamps = []\n",
    "last_audio_cue_time = -float('inf')\n",
    "\n",
    "def fire_rem_audio_cues_sequence_sim(current_time_seconds):\n",
    "    \"\"\"Simulates firing audio cues and records their timestamps.\"\"\"\n",
    "    global last_audio_cue_time, sim_metadata_audio_cue_timestamps\n",
    "    \n",
    "    print(f\"SIM AUDIO: Attempting to fire REM audio cue sequence at {current_time_seconds:.2f}s\")\n",
    "    for i in range(MAX_SUCCESSIVE_REM_CUES):\n",
    "        cue_initiation_time = current_time_seconds + (i * REM_AUDIO_CUE_INTERVAL_SECONDS)\n",
    "        # Check if enough time has passed since the *very last* cue of any sequence\n",
    "        # This is a simplified check for simulation; real app might have more complex state\n",
    "        if cue_initiation_time < last_audio_cue_time + REM_AUDIO_CUE_INTERVAL_SECONDS: \n",
    "            # This check is mostly to prevent overlapping print statements in rapid succession if called improperly\n",
    "            # The main loop's `is_in_rem_cycle` and `rem_audio_cues_fired_this_cycle` should prevent re-triggering too soon.\n",
    "            print(f\"SIM AUDIO: Cue {i+1} at {cue_initiation_time:.2f}s would be too soon. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        sim_metadata_audio_cue_timestamps.append(cue_initiation_time)\n",
    "        print(f\"SIM AUDIO: Cue {i+1}/{MAX_SUCCESSIVE_REM_CUES} scheduled/fired at {cue_initiation_time:.2f}s (Simulated)\")\n",
    "        last_audio_cue_time = cue_initiation_time\n",
    "        \n",
    "        # In a real simulation, you might want to simulate the time passing for the cue duration\n",
    "        # For this, we just record the timestamp of when it *would* play.\n",
    "    return True # Indicates sequence was initiated\n",
    "\n",
    "print(\"Simulated audio cue function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c7ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import resample_poly\n",
    "import math \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime, timezone, timedelta\n",
    "import scipy.signal\n",
    "import time # Added time import for verbosity\n",
    "\n",
    "# This cell should be run after the previous cells defining constants, helpers, and importing predict_alertness_ema\n",
    "\n",
    "def real_time_processing_simulation(\n",
    "    eeg_data_original, \n",
    "    fs_original, \n",
    "    fs_target, \n",
    "    stages_df_sim, \n",
    "    simulation_duration_seconds_sim, \n",
    "    session_start_iso_sim, # This is the correct parameter name\n",
    "    sim_stage_interval_seconds, # Interval for sleep stage updates\n",
    "    sim_total_stages_count, # Total number of stage entries\n",
    "    eeg_channels_to_use_sim # List of EEG channel names used\n",
    "):\n",
    "    \"\"\"\n",
    "    Simulates the real-time processing loop using pre-recorded data.\n",
    "    Uses actual alertness detection model.\n",
    "    \"\"\"\n",
    "    print(f\"Simulation starting with duration: {simulation_duration_seconds_sim}s, Target FS: {fs_target}Hz\")\n",
    "    print(f\"EEG channels used in simulation: {eeg_channels_to_use_sim}\") # Expecting one channel for current model\n",
    "\n",
    "    # Ensure eeg_data_original is 2D (channels, samples) and select the first channel if multiple\n",
    "    if eeg_data_original.ndim == 1:\n",
    "        eeg_data_original = eeg_data_original.reshape(1, -1) # Make it (1, samples)\n",
    "    \n",
    "    # For the current DeepSleepNet model, it expects single channel EEG data.\n",
    "    # If eeg_channels_to_use_sim has more than one, we should select one or average.\n",
    "    # For now, assuming the loaded eeg_data corresponds to the single channel expected by the model.\n",
    "    # If eeg_data_original has multiple channels, let's pick the first one specified in eeg_channels_to_use_sim\n",
    "    # This logic assumes eeg_data_original was loaded considering eeg_channels_to_use_sim from cell 1\n",
    "    # For simplicity, if eeg_data_original still has multiple channels here, we take the first one.\n",
    "    if eeg_data_original.shape[0] > 1:\n",
    "        print(f\"Warning: Original EEG data has {eeg_data_original.shape[0]} channels. Using the first channel for alertness prediction.\")\n",
    "        eeg_single_channel_original = eeg_data_original[0, :]\n",
    "    else:\n",
    "        eeg_single_channel_original = eeg_data_original.squeeze() # Ensure it's 1D\n",
    "\n",
    "    # Resample the selected EEG channel data\n",
    "    num_original_samples = len(eeg_single_channel_original)\n",
    "    num_target_samples = int(num_original_samples * fs_target / fs_original)\n",
    "    eeg_resampled = scipy.signal.resample(eeg_single_channel_original, num_target_samples)\n",
    "    print(f\"EEG data resampled from {num_original_samples} to {num_target_samples} samples.\")\n",
    "\n",
    "    # Simulation loop variables\n",
    "    sim_timestamps = []\n",
    "    sim_sleep_stages = []\n",
    "    sim_alertness_scores = []\n",
    "    \n",
    "    # Declare global and clear before use in this function\n",
    "    global sim_metadata_audio_cue_timestamps\n",
    "    # sim_metadata_audio_cue_timestamps is already global from cell ffbe0495, clear it for new run\n",
    "    # Ensure it exists in global scope if this cell is run independently of cell ffbe0495 for some reason\n",
    "    if 'sim_metadata_audio_cue_timestamps' not in globals():\n",
    "        sim_metadata_audio_cue_timestamps = [] \n",
    "    else:\n",
    "        sim_metadata_audio_cue_timestamps.clear()\n",
    "\n",
    "    last_rem_audio_cue_time = -float('inf')\n",
    "    successive_rem_cues_fired = 0\n",
    "    current_alertness_ema_sim = 0.5 # Initial value\n",
    "\n",
    "    # Buffer for EEG data for alertness model (needs `needed_len` samples)\n",
    "    eeg_buffer_alertness = np.zeros(needed_len) # Initialize with zeros\n",
    "    \n",
    "    total_windows = int(simulation_duration_seconds_sim // SECONDS_PER_WINDOW)\n",
    "    print(f\"Total windows to process: {total_windows}\")\n",
    "\n",
    "    for i in range(total_windows):\n",
    "        current_sim_time_seconds = i * SECONDS_PER_WINDOW\n",
    "        # print(f\"Simulating time: {current_sim_time_seconds:.2f}s\") # Verbose\n",
    "\n",
    "        # 1. Get current sleep stage\n",
    "        current_sleep_stage = get_sleep_stage_at_time(\n",
    "            current_sim_time_seconds, \n",
    "            session_start_iso_sim,  # Corrected variable name\n",
    "            stages_df_sim, \n",
    "            sim_stage_interval_seconds,\n",
    "            sim_total_stages_count\n",
    "        )\n",
    "\n",
    "        # 2. Get EEG data for the current window (1 second)\n",
    "        start_sample_idx = int(current_sim_time_seconds * fs_target)\n",
    "        end_sample_idx = start_sample_idx + int(SECONDS_PER_WINDOW * fs_target)\n",
    "        \n",
    "        if end_sample_idx > len(eeg_resampled):\n",
    "            print(f\"Reached end of resampled EEG data at {current_sim_time_seconds}s. Stopping simulation.\")\n",
    "            break\n",
    "        \n",
    "        current_eeg_window = eeg_resampled[start_sample_idx:end_sample_idx]\n",
    "\n",
    "        # 3. Update EEG buffer for alertness model\n",
    "        # Shift buffer and add new data\n",
    "        eeg_buffer_alertness = np.roll(eeg_buffer_alertness, -len(current_eeg_window))\n",
    "        eeg_buffer_alertness[-len(current_eeg_window):] = current_eeg_window\n",
    "\n",
    "        # 4. Predict alertness (if buffer has enough data)\n",
    "        # The model expects `needed_len` samples. We feed it every second.\n",
    "        # The `predict_alertness_ema` function itself handles chunking internally based on its own `input_len` and `seq_len`.\n",
    "        if i * SECONDS_PER_WINDOW * fs_target >= needed_len: # Ensure we have at least needed_len of data processed into buffer\n",
    "            # The function expects the raw segment of `needed_len`\n",
    "            # The current eeg_buffer_alertness *is* that segment.\n",
    "            current_alertness_ema_sim = predict_alertness_ema(eeg_buffer_alertness, ema_span=20) # ema_span is internal to func\n",
    "        else:\n",
    "            # Not enough data yet for a full prediction, use initial/previous or a placeholder\n",
    "            current_alertness_ema_sim = 0.5 # Or some other strategy\n",
    "            # print(f\"Not enough data for alertness prediction yet. Current buffer filled: {i * SECONDS_PER_WINDOW * fs_target / needed_len * 100:.1f}%\")\n",
    "\n",
    "        # 5. REM Detection and Audio Cue Logic (Simplified)\n",
    "        is_rem_sleep = (current_sleep_stage == REM_SLEEP_STAGE_VALUE)\n",
    "        \n",
    "        if is_rem_sleep:\n",
    "            # print(f\"REM detected at {current_sim_time_seconds:.2f}s. Alertness: {current_alertness_ema_sim:.2f}\")\n",
    "            can_fire_due_to_interval = (current_sim_time_seconds - last_rem_audio_cue_time) >= REM_AUDIO_CUE_INTERVAL_SECONDS\n",
    "            can_fire_due_to_successive_limit = successive_rem_cues_fired < MAX_SUCCESSIVE_REM_CUES\n",
    "            \n",
    "            if can_fire_due_to_interval and can_fire_due_to_successive_limit:\n",
    "                print(f\"  Firing REM audio cue sequence at {current_sim_time_seconds:.2f}s. Successive count: {successive_rem_cues_fired + 1}\")\n",
    "                fire_rem_audio_cues_sequence_sim(current_sim_time_seconds) # Records to global list\n",
    "                last_rem_audio_cue_time = current_sim_time_seconds \n",
    "                successive_rem_cues_fired += 1\n",
    "            elif not can_fire_due_to_interval:\n",
    "                # print(f\"  REM cue suppressed: Interval not met. Last cue at {last_rem_audio_cue_time:.2f}s\")\n",
    "                pass # Interval not met\n",
    "            elif not can_fire_due_to_successive_limit:\n",
    "                # print(f\"  REM cue suppressed: Max successive cues reached.\")\n",
    "                pass # Max successive cues reached\n",
    "        else:\n",
    "            # Not in REM, reset successive cue counter\n",
    "            if successive_rem_cues_fired > 0:\n",
    "                # print(f\"Exited REM or not in REM. Resetting successive REM cue counter from {successive_rem_cues_fired}.\")\n",
    "                pass\n",
    "            successive_rem_cues_fired = 0\n",
    "            \n",
    "        # Store metadata for this second\n",
    "        sim_timestamps.append(current_sim_time_seconds)\n",
    "        sim_sleep_stages.append(current_sleep_stage)\n",
    "        sim_alertness_scores.append(current_alertness_ema_sim)\n",
    "\n",
    "        if (i + 1) % (10 * SECONDS_PER_WINDOW) == 0: # Print progress every 10 seconds of simulation\n",
    "            print(f\"Progress: {current_sim_time_seconds:.0f}s / {simulation_duration_seconds_sim:.0f}s. Stage: {current_sleep_stage}, Alertness: {current_alertness_ema_sim:.3f}\")\n",
    "\n",
    "    print(\"Simulation loop finished.\")\n",
    "    \n",
    "    # Prepare results\n",
    "    results = {\n",
    "        \"timestamps\": np.array(sim_timestamps),\n",
    "        \"sleep_stages\": np.array(sim_sleep_stages),\n",
    "        \"alertness_scores\": np.array(sim_alertness_scores),\n",
    "        \"audio_cue_timestamps\": np.array(sim_metadata_audio_cue_timestamps),\n",
    "        \"fs_target\": fs_target,\n",
    "        \"simulation_duration_seconds\": simulation_duration_seconds_sim,\n",
    "        \"session_start_iso\": session_start_iso_sim,\n",
    "        \"sleep_stage_interval_simulated\": sim_stage_interval_seconds,\n",
    "        \"eeg_channels_used\": eeg_channels_to_use_sim\n",
    "    }\n",
    "    return results\n",
    "\n",
    "print(\"Simulation loop function `real_time_processing_simulation` defined and ready.\")\n",
    "# Example of how to call (actual call will be in a new cell):\n",
    "# sim_results = real_time_processing_simulation(\n",
    "#     eeg_data, # from cell 1\n",
    "#     FS_ORIGINAL, # from cell 1\n",
    "#     FS_TARGET, # from cell 2\n",
    "#     stages_df, # from cell 1\n",
    "#     simulation_duration_seconds, # from cell 1\n",
    "#     session_start_time_utc.isoformat(), # from cell 1\n",
    "#     sleep_stage_interval_seconds, # from cell 1\n",
    "#     n_sleep_stages_entries, # from cell 1\n",
    "#     EEG_CHANNELS_TO_USE # from cell 1\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c72a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Execute the Simulation ---\n",
    "# This cell assumes all previous cells (data loading, helpers, simulation function) have been run.\n",
    "\n",
    "print(\"Starting simulation execution...\")\n",
    "\n",
    "# Ensure global list for audio cues is initialized if not already by cell ffbe0495\n",
    "if 'sim_metadata_audio_cue_timestamps' not in globals():\n",
    "    sim_metadata_audio_cue_timestamps = []\n",
    "else:\n",
    "    sim_metadata_audio_cue_timestamps.clear() # Clear for a fresh run\n",
    "\n",
    "# Call the simulation function with variables loaded/defined in previous cells\n",
    "# These variables should be in the global notebook scope from executing Cell 1 (b00d3c33) and Cell 2 (921c860b)\n",
    "sim_results = real_time_processing_simulation(\n",
    "    eeg_data,                   # Loaded in Cell 1 (b00d3c33)\n",
    "    FS_ORIGINAL,                # Defined in Cell 1 (b00d3c33)\n",
    "    FS_TARGET,                  # Defined in Cell 2 (921c860b)\n",
    "    stages_df,                  # Loaded in Cell 1 (b00d3c33)\n",
    "    simulation_duration_seconds,# Calculated in Cell 1 (b00d3c33)\n",
    "    session_start_time_utc.isoformat(), # Corrected: Convert datetime object to ISO string\n",
    "    sleep_stage_interval_seconds, # Calculated in Cell 1 (b00d3c33)\n",
    "    n_sleep_stages_entries,     # Calculated in Cell 1 (b00d3c33)\n",
    "    EEG_CHANNELS_TO_USE         # Defined in Cell 1 (b00d3c33)\n",
    ")\n",
    "\n",
    "print(\"Simulation finished. Results dictionary created.\")\n",
    "print(f\"Number of audio cues triggered: {len(sim_results['audio_cue_timestamps'])}\")\n",
    "print(f\"First few alertness scores: {sim_results['alertness_scores'][:10]}\")\n",
    "print(f\"Simulated sleep stage interval: {sim_results['sleep_stage_interval_simulated']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60b362c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Simulation Results ---\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "output_filename = \"simulation_results.npz\"\n",
    "output_path = os.path.join(WORKSPACE_ROOT, output_filename) # Save in workspace root\n",
    "\n",
    "if 'sim_results' in globals():\n",
    "    try:\n",
    "        np.savez_compressed(output_path, **sim_results)\n",
    "        print(f\"Simulation results successfully saved to: {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving simulation results: {e}\")\n",
    "else:\n",
    "    print(\"'sim_results' not found. Please run the simulation cell first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd68299d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Plot Simulation Results ---\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Assuming WORKSPACE_ROOT is defined (e.g., from cell 921c860b or defined here again)\n",
    "if 'WORKSPACE_ROOT' not in globals():\n",
    "    WORKSPACE_ROOT = '/Users/suryaven/Documents/code/uni/neurotech/lucid-dreaming-core'\n",
    "\n",
    "results_filename = \"simulation_results.npz\"\n",
    "results_path = os.path.join(WORKSPACE_ROOT, results_filename)\n",
    "\n",
    "if not os.path.exists(results_path):\n",
    "    print(f\"Results file not found at {results_path}. Please run the saving cell first.\")\n",
    "else:\n",
    "    try:\n",
    "        data = np.load(results_path, allow_pickle=True)\n",
    "        print(\"Loaded data keys:\", list(data.keys()))\n",
    "\n",
    "        timestamps = data['timestamps']\n",
    "        sleep_stages = data['sleep_stages']\n",
    "        alertness_scores = data['alertness_scores']\n",
    "        audio_cue_timestamps = data['audio_cue_timestamps']\n",
    "        print(audio_cue_timestamps)\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(15, 7))\n",
    "\n",
    "        # Plot sleep stages on primary y-axis\n",
    "        color = 'tab:blue'\n",
    "        ax1.set_xlabel('Time (s)')\n",
    "        ax1.set_ylabel('Sleep Stage', color=color)\n",
    "        ax1.plot(timestamps, sleep_stages, color=color, linestyle='-', marker='.', label='Sleep Stage')\n",
    "        ax1.tick_params(axis='y', labelcolor=color)\n",
    "        ax1.set_yticks(np.unique(sleep_stages)) # Show actual stage values on y-axis\n",
    "        # Remap sleep stage values to names for clarity if desired, e.g. using a dictionary\n",
    "        # sleep_stage_names = {0: 'Wake', 1: 'N1', 2: 'N2', 3: 'REM', 4: 'N3'} # Example mapping\n",
    "        # ax1.set_yticklabels([sleep_stage_names.get(stage, str(stage)) for stage in np.unique(sleep_stages)])\n",
    "\n",
    "        # Create a secondary y-axis for alertness scores\n",
    "        ax2 = ax1.twinx()\n",
    "        color = 'tab:red'\n",
    "        ax2.set_ylabel('Alertness Score (EMA)', color=color)  # we already handled the x-label with ax1\n",
    "        ax2.plot(timestamps, alertness_scores, color=color, linestyle='--', label='Alertness Score')\n",
    "        ax2.tick_params(axis='y', labelcolor=color)\n",
    "        ax2.set_ylim(0, 1) # Alertness score is between 0 and 1\n",
    "\n",
    "        # Plot audio cue triggers as vertical lines\n",
    "        if len(audio_cue_timestamps) > 0:\n",
    "            for cue_time in audio_cue_timestamps:\n",
    "                ax1.axvline(x=cue_time, color='tab:green', linestyle=':', linewidth=2, label='Audio Cue (REM)' if 'Audio Cue (REM)' not in [l.get_label() for l in ax1.lines] else \"\")\n",
    "        \n",
    "        # Add a title and legend\n",
    "        plt.title('Simulation Results: Sleep Stages, Alertness, and Audio Cues')\n",
    "        fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "        \n",
    "        # Combine legends from both axes\n",
    "        lines, labels = ax1.get_legend_handles_labels()\n",
    "        lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "        # Add dummy entry for axvline if cues were plotted\n",
    "        if len(audio_cue_timestamps) > 0 and not any('Audio Cue (REM)' in l for l in labels + labels2):\n",
    "             # Create a proxy artist for the legend if not already created by plot\n",
    "            from matplotlib.lines import Line2D\n",
    "            proxy_line = Line2D([0], [0], linestyle=':', color='tab:green', linewidth=2, label='Audio Cue (REM)')\n",
    "            lines.append(proxy_line)\n",
    "            labels.append('Audio Cue (REM)')\n",
    "\n",
    "        ax2.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error plotting results: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
