{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=2360268\n",
      "    Range : 0 ... 2360267 =      0.000 ... 18882.136 secs\n",
      "Ready.\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.35 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.35\n",
      "- Lower transition bandwidth: 0.35 Hz (-6 dB cutoff frequency: 0.17 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1179 samples (9.432 s)\n",
      "\n",
      "realtime data epochs shape: (6285, 3000)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import numpy as np\n",
    "\n",
    "STRIDE_SEC = 3\n",
    "EPOCH_SEC_SIZE = 30\n",
    "channel_eeg = 6\n",
    "\n",
    "memmap_eeg_data = np.memmap('/Users/lejieliu/Documents/CS189/lucid-dreaming-core/app/recorded_data/20250530_060058_350200/1748599265.051497/eeg.dat', dtype=np.float64, mode='r')\n",
    "l_eeg = int(len(memmap_eeg_data)//channel_eeg)\n",
    "\n",
    "eeg_data = np.array(memmap_eeg_data)[:l_eeg*channel_eeg].reshape((l_eeg, channel_eeg))\n",
    "\n",
    "raw_data = eeg_data[:, [0, 1, 3, 4]].T * 1e-8\n",
    "\n",
    "\n",
    "\n",
    "channel_names = ['LF-FpZ', 'OTE_L-FpZ', 'RF-FpZ', 'OTE_R-FpZ']\n",
    "sfreq = 125 \n",
    "\n",
    "info = mne.create_info(\n",
    "    ch_names=channel_names,\n",
    "    sfreq=sfreq,\n",
    "    ch_types=[\"eeg\"] * len(channel_names)\n",
    ")\n",
    "\n",
    "raw = mne.io.RawArray(raw_data, info)\n",
    "raw.pick_channels(['RF-FpZ'])\n",
    "raw.filter(0.35, 40)\n",
    "raw = raw.resample(100)\n",
    "sfreq = 100\n",
    "data = raw.to_data_frame()['RF-FpZ']\n",
    "n_samples = len(data)\n",
    "\n",
    "epoch_len = int(EPOCH_SEC_SIZE * sfreq)\n",
    "stride_len = int(STRIDE_SEC * sfreq)\n",
    "\n",
    "n_epoch = (n_samples - epoch_len) // stride_len + 1\n",
    "\n",
    "epochs = []\n",
    "labels = []\n",
    "for i in range(n_epoch):\n",
    "    start = i * stride_len\n",
    "    end = start + epoch_len\n",
    "    if end > n_samples:\n",
    "        break\n",
    "    epoch_data = np.array(data[start:end])\n",
    "\n",
    "    # z-score\n",
    "    m = np.mean(epoch_data)\n",
    "    s = np.std(epoch_data) + 1e-8\n",
    "    epoch_data = (epoch_data - m) / s\n",
    "\n",
    "    epochs.append(epoch_data)\n",
    "\n",
    "epochs = np.stack(epochs, axis=0) if epochs else np.empty((0, 1, epoch_len))\n",
    "\n",
    "print(\"realtime data epochs shape:\", epochs.shape)  # (n_epoch, n_channels, epoch_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "class DeepSleepNetBinary(nn.Module):\n",
    "    def __init__(self, input_len=3000, cnn_feat_dim=128, lstm_hidden=128, seq_len=20):\n",
    "        super().__init__()\n",
    "        # Multi-scale CNN branch 1 (large kernel)\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=400, stride=50, padding=0),  # (batch, 64, ?)\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4),\n",
    "            nn.Conv1d(64, 128, kernel_size=6, stride=1, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=6, stride=1, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=6, stride=1, padding=3),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(2)\n",
    "        )\n",
    "        # Multi-scale CNN branch 2 (small kernel)\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(1, 64, kernel_size=50, stride=6, padding=0),  # (batch, 64, ?)\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(8),\n",
    "            nn.Conv1d(64, 128, kernel_size=8, stride=1, padding=4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=8, stride=1, padding=4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(128, 128, kernel_size=8, stride=1, padding=4),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool1d(4)\n",
    "        )\n",
    "        # 计算flatten后输出的特征维度\n",
    "        with torch.no_grad():\n",
    "            dummy = torch.randn(1, 1, input_len)\n",
    "            feat1 = self.cnn1(dummy).view(1, -1).shape[1]\n",
    "            feat2 = self.cnn2(dummy).view(1, -1).shape[1]\n",
    "        self.cnn_out_dim = feat1 + feat2\n",
    "\n",
    "        # 全连接用于 residual shortcut，输出改为256\n",
    "        self.fc_residual = nn.Sequential(\n",
    "            nn.Linear(self.cnn_out_dim, 256),  # <--- 改这里\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        # LSTM for sequence modeling\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=self.cnn_out_dim,\n",
    "            hidden_size=lstm_hidden,\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            dropout=0.5,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        # Output layer: binary classification\n",
    "        self.final_fc = nn.Sequential(\n",
    "            nn.Linear(lstm_hidden * 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (batch, seq_len, 3000)\n",
    "        b, t, n = x.shape\n",
    "        x = x.view(b * t, 1, n)  # (batch*seq, 1, 3000)\n",
    "        # Multi-scale CNN\n",
    "        x1 = self.cnn1(x).view(b * t, -1)\n",
    "        x2 = self.cnn2(x).view(b * t, -1)\n",
    "        cnn_feat = torch.cat([x1, x2], dim=1)  # (batch*seq, feat)\n",
    "        # Residual shortcut\n",
    "        res_feat = self.fc_residual(cnn_feat)  # (batch*seq, 256)\n",
    "        # Reshape for LSTM\n",
    "        cnn_feat_seq = cnn_feat.view(b, t, -1)  # (batch, seq_len, feat)\n",
    "        # LSTM\n",
    "        lstm_out, _ = self.lstm(cnn_feat_seq)\n",
    "        # 用最后一个时刻的 LSTM 输出\n",
    "        lstm_last = lstm_out[:, -1, :]  # (batch, hidden*2=256)\n",
    "        # Add residual (res_feat 对应最后一帧)\n",
    "        res_feat_seq = res_feat.view(b, t, -1)[:, -1, :]  # (batch, 256)\n",
    "        fused = lstm_last + res_feat_seq  # (batch, 256)\n",
    "        # Output\n",
    "        logits = self.final_fc(fused).squeeze(1)  # (batch,)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepSleepNetBinary(\n",
       "  (cnn1): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(400,), stride=(50,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(6,), stride=(1,), padding=(3,))\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Conv1d(128, 128, kernel_size=(6,), stride=(1,), padding=(3,))\n",
       "    (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): Conv1d(128, 128, kernel_size=(6,), stride=(1,), padding=(3,))\n",
       "    (11): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (cnn2): Sequential(\n",
       "    (0): Conv1d(1, 64, kernel_size=(50,), stride=(6,))\n",
       "    (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool1d(kernel_size=8, stride=8, padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): Conv1d(64, 128, kernel_size=(8,), stride=(1,), padding=(4,))\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=(4,))\n",
       "    (8): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (9): ReLU()\n",
       "    (10): Conv1d(128, 128, kernel_size=(8,), stride=(1,), padding=(4,))\n",
       "    (11): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (12): ReLU()\n",
       "    (13): MaxPool1d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc_residual): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "  )\n",
       "  (lstm): LSTM(3072, 128, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (final_fc): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fs = 100\n",
    "seq_len = 5\n",
    "epoch_sec = 30\n",
    "input_len = epoch_sec * fs    \n",
    "model_weight_path = '/Users/lejieliu/Documents/CS189/lucid-dreaming-core/models/alertness_torch_weights_salt.pth'\n",
    "\n",
    "model = DeepSleepNetBinary(input_len=3000, seq_len=seq_len)\n",
    "model.load_state_dict(torch.load(model_weight_path, map_location='cpu'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测结果 shape: (6281,)\n"
     ]
    }
   ],
   "source": [
    "seq_len = 5\n",
    "X_seq = []\n",
    "for i in range(len(epochs) - seq_len + 1):\n",
    "    X_seq.append(epochs[i:i+seq_len])\n",
    "X_seq = np.stack(X_seq, axis=0)\n",
    "\n",
    "model.eval()\n",
    "y_pred_list = []\n",
    "batch_size = 64\n",
    "\n",
    "X_seq_tensor = torch.tensor(X_seq, dtype=torch.float32)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, len(X_seq_tensor), batch_size):\n",
    "        xb = X_seq_tensor[i:i+batch_size]\n",
    "        logits = model(xb)\n",
    "        # 如果是sigmoid二分类\n",
    "        probs = 1 - torch.sigmoid(logits).cpu().numpy().flatten()\n",
    "        y_pred_list.append(probs)\n",
    "\n",
    "y_pred = np.concatenate(y_pred_list)\n",
    "print(\"预测结果 shape:\", y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_alertness_ema(eeg_raw, ema_span=200):\n",
    "\n",
    "    if not hasattr(predict_alertness_ema, \"alertness_history\"):\n",
    "        predict_alertness_ema.alertness_history = []\n",
    "\n",
    "    channel_names = ['LF-FpZ', 'OTE_L-FpZ', 'RF-FpZ', 'OTE_R-FpZ']\n",
    "    sfreq = 125 \n",
    "\n",
    "    info = mne.create_info(\n",
    "        ch_names=channel_names,\n",
    "        sfreq=sfreq,\n",
    "        ch_types=[\"eeg\"] * len(channel_names)\n",
    "    )\n",
    "\n",
    "    raw = mne.io.RawArray(eeg_raw, info)\n",
    "    raw.pick_channels(['RF-FpZ'])\n",
    "\n",
    "    raw.filter(0.35, 40)\n",
    "    raw = raw.resample(100)\n",
    "    sfreq = 100\n",
    "\n",
    "    eeg_raw = raw.to_data_frame()['RF-FpZ'].to_numpy()\n",
    "    # 分chunk\n",
    "    chunks = [eeg_raw[i*input_len : (i+1)*input_len] for i in range(seq_len)]\n",
    "    # 每个epoch做z-score\n",
    "    chunks_zscore = []\n",
    "    for arr in chunks:\n",
    "        arr = np.asarray(arr)\n",
    "        m = arr.mean()\n",
    "        s = arr.std() + 1e-8\n",
    "        arr_norm = (arr - m) / s\n",
    "        chunks_zscore.append(arr_norm)\n",
    "    segs = np.stack(chunks_zscore, axis=0)     # (seq_len, input_len)\n",
    "    segs = segs[None, :, None :]          \n",
    "    x_tensor = torch.from_numpy(segs.astype(np.float32))\n",
    "    with torch.no_grad():\n",
    "        out = model(x_tensor)\n",
    "        alertness_score = (1 - torch.sigmoid(out).item())\n",
    "    predict_alertness_ema.alertness_history.append(alertness_score)\n",
    "    series = pd.Series(predict_alertness_ema.alertness_history)\n",
    "    # ewm_score = series.ewm(span=ema_span, adjust=False).mean().iloc[-1]\n",
    "\n",
    "    return alertness_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=18750\n",
      "    Range : 0 ... 18749 =      0.000 ...   149.992 secs\n",
      "Ready.\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.35 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.35\n",
      "- Lower transition bandwidth: 0.35 Hz (-6 dB cutoff frequency: 0.17 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1179 samples (9.432 s)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005168497562408447"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_alertness_ema(raw_data[:, (s_len) * 21: (s_len) * 22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=4, n_times=15000\n",
      "    Range : 0 ... 14999 =      0.000 ...   119.992 secs\n",
      "Ready.\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.35 - 40 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 0.35\n",
      "- Lower transition bandwidth: 0.35 Hz (-6 dB cutoff frequency: 0.17 Hz)\n",
      "- Upper passband edge: 40.00 Hz\n",
      "- Upper transition bandwidth: 10.00 Hz (-6 dB cutoff frequency: 45.00 Hz)\n",
      "- Filter length: 1179 samples (9.432 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/68/l7xp6fns3w92gfhrl5cn9x940000gn/T/ipykernel_57881/3303704789.py:26: RuntimeWarning: Mean of empty slice.\n",
      "  m = arr.mean()\n",
      "/opt/anaconda3/envs/frenz-env/lib/python3.9/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/opt/anaconda3/envs/frenz-env/lib/python3.9/site-packages/numpy/core/_methods.py:206: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "/opt/anaconda3/envs/frenz-env/lib/python3.9/site-packages/numpy/core/_methods.py:163: RuntimeWarning: invalid value encountered in divide\n",
      "  arrmean = um.true_divide(arrmean, div, out=arrmean,\n",
      "/opt/anaconda3/envs/frenz-env/lib/python3.9/site-packages/numpy/core/_methods.py:198: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all input arrays must have the same shape",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[88], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m     arr_norm \u001b[38;5;241m=\u001b[39m (arr \u001b[38;5;241m-\u001b[39m m) \u001b[38;5;241m/\u001b[39m s\n\u001b[1;32m     29\u001b[0m     chunks_zscore\u001b[38;5;241m.\u001b[39mappend(arr_norm)\n\u001b[0;32m---> 30\u001b[0m segs \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks_zscore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m     \u001b[38;5;66;03m# (seq_len, input_len)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# segs = segs[None, :, :]          \u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# x_tensor = torch.from_numpy(segs.astype(np.float32))\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# series = pd.Series(predict_alertness_ema.alertness_history)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# ewm_score = series.ewm(span=ema_span, adjust=False).mean().iloc[-1]\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/frenz-env/lib/python3.9/site-packages/numpy/core/shape_base.py:449\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(arrays, axis, out, dtype, casting)\u001b[0m\n\u001b[1;32m    447\u001b[0m shapes \u001b[38;5;241m=\u001b[39m {arr\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays}\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(shapes) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 449\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall input arrays must have the same shape\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    451\u001b[0m result_ndim \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    452\u001b[0m axis \u001b[38;5;241m=\u001b[39m normalize_axis_index(axis, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all input arrays must have the same shape"
     ]
    }
   ],
   "source": [
    "eeg_raw = raw_data[:, (s_len) * 10: (s_len) * 11]\n",
    "\n",
    "channel_names = ['LF-FpZ', 'OTE_L-FpZ', 'RF-FpZ', 'OTE_R-FpZ']\n",
    "sfreq = 125 \n",
    "\n",
    "info = mne.create_info(\n",
    "    ch_names=channel_names,\n",
    "    sfreq=sfreq,\n",
    "    ch_types=[\"eeg\"] * len(channel_names)\n",
    ")\n",
    "\n",
    "raw = mne.io.RawArray(eeg_raw, info)\n",
    "raw.pick_channels(['RF-FpZ'])\n",
    "\n",
    "raw.filter(0.35, 40)\n",
    "raw = raw.resample(100)\n",
    "sfreq = 100\n",
    "\n",
    "eeg_raw = raw.to_data_frame()['RF-FpZ']\n",
    "# # 分chunk\n",
    "chunks = [eeg_raw[i*input_len : (i+1)*input_len] for i in range(seq_len)]\n",
    "# # 每个epoch做z-score\n",
    "chunks_zscore = []\n",
    "for arr in chunks:\n",
    "    arr = np.asarray(arr)\n",
    "    m = arr.mean()\n",
    "    s = arr.std() + 1e-8\n",
    "    arr_norm = (arr - m) / s\n",
    "    chunks_zscore.append(arr_norm)\n",
    "segs = np.stack(chunks_zscore, axis=0)     # (seq_len, input_len)\n",
    "# segs = segs[None, :, :]          \n",
    "# x_tensor = torch.from_numpy(segs.astype(np.float32))\n",
    "# with torch.no_grad():\n",
    "#     out = model(x_tensor)\n",
    "#     alertness_score = (1 - torch.sigmoid(out).cpu())\n",
    "# predict_alertness_ema.alertness_history.append(alertness_score)\n",
    "# series = pd.Series(predict_alertness_ema.alertness_history)\n",
    "# ewm_score = series.ewm(span=ema_span, adjust=False).mean().iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0      -0.014617\n",
       " 1      -0.128112\n",
       " 2      -0.267790\n",
       " 3      -0.272837\n",
       " 4      -0.325164\n",
       "           ...   \n",
       " 2995    0.008917\n",
       " 2996    0.026943\n",
       " 2997    0.037734\n",
       " 2998    0.013922\n",
       " 2999    0.045413\n",
       " Name: RF-FpZ, Length: 3000, dtype: float64,\n",
       " 3000    0.056743\n",
       " 3001    0.012927\n",
       " 3002    0.049927\n",
       " 3003    0.021675\n",
       " 3004    0.044819\n",
       "           ...   \n",
       " 5995   -0.109865\n",
       " 5996   -0.129007\n",
       " 5997   -0.088149\n",
       " 5998   -0.152024\n",
       " 5999   -0.105922\n",
       " Name: RF-FpZ, Length: 3000, dtype: float64,\n",
       " 6000   -0.124132\n",
       " 6001   -0.110951\n",
       " 6002   -0.064540\n",
       " 6003   -0.123173\n",
       " 6004   -0.128260\n",
       "           ...   \n",
       " 8995    0.050593\n",
       " 8996    0.021622\n",
       " 8997    0.034322\n",
       " 8998    0.032105\n",
       " 8999    0.083233\n",
       " Name: RF-FpZ, Length: 3000, dtype: float64,\n",
       " 9000     0.054546\n",
       " 9001     0.042081\n",
       " 9002     0.058861\n",
       " 9003     0.099840\n",
       " 9004     0.087674\n",
       "            ...   \n",
       " 11995   -0.060601\n",
       " 11996   -0.028483\n",
       " 11997    0.035369\n",
       " 11998    0.011061\n",
       " 11999   -0.005767\n",
       " Name: RF-FpZ, Length: 3000, dtype: float64,\n",
       " Series([], Name: RF-FpZ, dtype: float64)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
